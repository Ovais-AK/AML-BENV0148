{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HjdywvlqXoLT",
        "outputId": "ca2c1406-00a5-49fd-b474-1ca925d034ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in c:\\users\\james\\anaconda3\\lib\\site-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\james\\anaconda3\\lib\\site-packages (3.7.1)\n",
            "Requirement already satisfied: zarr in c:\\users\\james\\anaconda3\\lib\\site-packages (2.17.1)\n",
            "Requirement already satisfied: xarray in c:\\users\\james\\anaconda3\\lib\\site-packages (0.20.1)\n",
            "Requirement already satisfied: ipykernel in c:\\users\\james\\anaconda3\\lib\\site-packages (6.15.2)\n",
            "Requirement already satisfied: gcsfs in c:\\users\\james\\anaconda3\\lib\\site-packages (2024.3.1)\n",
            "Requirement already satisfied: fsspec in c:\\users\\james\\anaconda3\\lib\\site-packages (2024.3.1)\n",
            "Requirement already satisfied: dask in c:\\users\\james\\anaconda3\\lib\\site-packages (2022.7.0)\n",
            "Requirement already satisfied: cartopy in c:\\users\\james\\anaconda3\\lib\\site-packages (0.22.0)\n",
            "Requirement already satisfied: ocf-blosc2 in c:\\users\\james\\anaconda3\\lib\\site-packages (0.0.4)\n",
            "Requirement already satisfied: torchinfo in c:\\users\\james\\anaconda3\\lib\\site-packages (1.8.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from matplotlib) (5.12.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\james\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from matplotlib) (9.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\james\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\james\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\james\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\james\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from matplotlib) (21.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
            "Requirement already satisfied: numcodecs>=0.10.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from zarr) (0.12.1)\n",
            "Requirement already satisfied: fasteners in c:\\users\\james\\anaconda3\\lib\\site-packages (from zarr) (0.19)\n",
            "Requirement already satisfied: asciitree in c:\\users\\james\\anaconda3\\lib\\site-packages (from zarr) (0.3.3)\n",
            "Requirement already satisfied: pandas>=1.1 in c:\\users\\james\\anaconda3\\lib\\site-packages (from xarray) (2.2.1)\n",
            "Requirement already satisfied: nest-asyncio in c:\\users\\james\\anaconda3\\lib\\site-packages (from ipykernel) (1.5.5)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from ipykernel) (5.1.1)\n",
            "Requirement already satisfied: tornado>=6.1 in c:\\users\\james\\anaconda3\\lib\\site-packages (from ipykernel) (6.1)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\james\\anaconda3\\lib\\site-packages (from ipykernel) (0.1.6)\n",
            "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\james\\anaconda3\\lib\\site-packages (from ipykernel) (7.31.1)\n",
            "Requirement already satisfied: pyzmq>=17 in c:\\users\\james\\anaconda3\\lib\\site-packages (from ipykernel) (23.2.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\james\\anaconda3\\lib\\site-packages (from ipykernel) (7.3.4)\n",
            "Requirement already satisfied: psutil in c:\\users\\james\\anaconda3\\lib\\site-packages (from ipykernel) (5.9.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from ipykernel) (1.5.1)\n",
            "Requirement already satisfied: google-auth>=1.2 in c:\\users\\james\\anaconda3\\lib\\site-packages (from gcsfs) (2.28.2)\n",
            "Requirement already satisfied: google-auth-oauthlib in c:\\users\\james\\anaconda3\\lib\\site-packages (from gcsfs) (0.4.6)\n",
            "Requirement already satisfied: google-cloud-storage in c:\\users\\james\\anaconda3\\lib\\site-packages (from gcsfs) (2.16.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\james\\anaconda3\\lib\\site-packages (from gcsfs) (3.8.3)\n",
            "Requirement already satisfied: decorator>4.1.2 in c:\\users\\james\\anaconda3\\lib\\site-packages (from gcsfs) (5.1.1)\n",
            "Requirement already satisfied: requests in c:\\users\\james\\anaconda3\\lib\\site-packages (from gcsfs) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\james\\anaconda3\\lib\\site-packages (from dask) (6.0)\n",
            "Requirement already satisfied: toolz>=0.8.2 in c:\\users\\james\\anaconda3\\lib\\site-packages (from dask) (0.11.2)\n",
            "Requirement already satisfied: cloudpickle>=1.1.1 in c:\\users\\james\\anaconda3\\lib\\site-packages (from dask) (2.0.0)\n",
            "Requirement already satisfied: partd>=0.3.10 in c:\\users\\james\\anaconda3\\lib\\site-packages (from dask) (1.2.0)\n",
            "Requirement already satisfied: pyshp>=2.1 in c:\\users\\james\\anaconda3\\lib\\site-packages (from cartopy) (2.3.1)\n",
            "Requirement already satisfied: pyproj>=3.1.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from cartopy) (3.6.1)\n",
            "Requirement already satisfied: shapely>=1.7 in c:\\users\\james\\anaconda3\\lib\\site-packages (from cartopy) (2.0.3)\n",
            "Requirement already satisfied: blosc2 in c:\\users\\james\\anaconda3\\lib\\site-packages (from ocf-blosc2) (2.5.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\james\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\james\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (6.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (21.4.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\james\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.8.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (2.0.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\james\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\james\\anaconda3\\lib\\site-packages (from google-auth>=1.2->gcsfs) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from google-auth>=1.2->gcsfs) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\james\\anaconda3\\lib\\site-packages (from google-auth>=1.2->gcsfs) (4.9)\n",
            "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.8.0)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (3.0.20)\n",
            "Requirement already satisfied: pickleshare in c:\\users\\james\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.7.5)\n",
            "Requirement already satisfied: backcall in c:\\users\\james\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.2.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in c:\\users\\james\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (63.4.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\james\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.4.5)\n",
            "Requirement already satisfied: pygments in c:\\users\\james\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (2.17.2)\n",
            "Requirement already satisfied: jedi>=0.16 in c:\\users\\james\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.18.1)\n",
            "Requirement already satisfied: entrypoints in c:\\users\\james\\anaconda3\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel) (0.4)\n",
            "Requirement already satisfied: jupyter-core>=4.9.2 in c:\\users\\james\\anaconda3\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel) (4.11.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\james\\anaconda3\\lib\\site-packages (from pandas>=1.1->xarray) (2022.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\james\\anaconda3\\lib\\site-packages (from pandas>=1.1->xarray) (2024.1)\n",
            "Requirement already satisfied: locket in c:\\users\\james\\anaconda3\\lib\\site-packages (from partd>=0.3.10->dask) (1.0.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\james\\anaconda3\\lib\\site-packages (from pyproj>=3.1.0->cartopy) (2023.5.7)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\james\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: ndindex>=1.4 in c:\\users\\james\\anaconda3\\lib\\site-packages (from blosc2->ocf-blosc2) (1.8)\n",
            "Requirement already satisfied: py-cpuinfo in c:\\users\\james\\anaconda3\\lib\\site-packages (from blosc2->ocf-blosc2) (9.0.0)\n",
            "Requirement already satisfied: msgpack in c:\\users\\james\\anaconda3\\lib\\site-packages (from blosc2->ocf-blosc2) (1.0.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from google-auth-oauthlib->gcsfs) (1.3.1)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from google-cloud-storage->gcsfs) (1.5.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from google-cloud-storage->gcsfs) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media>=2.6.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from google-cloud-storage->gcsfs) (2.7.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from google-cloud-storage->gcsfs) (2.17.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\james\\anaconda3\\lib\\site-packages (from requests->gcsfs) (1.26.6)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\james\\anaconda3\\lib\\site-packages (from requests->gcsfs) (2.10)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\james\\anaconda3\\lib\\site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs) (1.63.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in c:\\users\\james\\anaconda3\\lib\\site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs) (4.25.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.3)\n",
            "Requirement already satisfied: pywin32>=1.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel) (302)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\james\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel) (0.2.5)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\james\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.2.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\james\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\james\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\james\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\james\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\james\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\james\\anaconda3\\lib\\site-packages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: doxa-cli in c:\\users\\james\\anaconda3\\lib\\site-packages (0.1.5)\n",
            "Collecting doxa-cli\n",
            "  Downloading doxa_cli-0.1.7-py3-none-any.whl (16 kB)\n",
            "Collecting requests~=2.26.0\n",
            "  Using cached requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "Requirement already satisfied: halo>=0.0.31,~=0.0.31 in c:\\users\\james\\anaconda3\\lib\\site-packages (from doxa-cli) (0.0.31)\n",
            "Requirement already satisfied: requests-toolbelt~=0.10.1 in c:\\users\\james\\anaconda3\\lib\\site-packages (from doxa-cli) (0.10.1)\n",
            "Requirement already satisfied: pyyaml>=6.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from doxa-cli) (6.0)\n",
            "Requirement already satisfied: typer[all]>=0.9.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from doxa-cli) (0.9.0)\n",
            "Requirement already satisfied: spinners>=0.0.24 in c:\\users\\james\\anaconda3\\lib\\site-packages (from halo>=0.0.31,~=0.0.31->doxa-cli) (0.0.24)\n",
            "Requirement already satisfied: log-symbols>=0.0.14 in c:\\users\\james\\anaconda3\\lib\\site-packages (from halo>=0.0.31,~=0.0.31->doxa-cli) (0.0.14)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from halo>=0.0.31,~=0.0.31->doxa-cli) (1.16.0)\n",
            "Requirement already satisfied: colorama>=0.3.9 in c:\\users\\james\\anaconda3\\lib\\site-packages (from halo>=0.0.31,~=0.0.31->doxa-cli) (0.4.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from halo>=0.0.31,~=0.0.31->doxa-cli) (2.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\james\\anaconda3\\lib\\site-packages (from requests~=2.26.0->doxa-cli) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from requests~=2.26.0->doxa-cli) (2.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\james\\anaconda3\\lib\\site-packages (from requests~=2.26.0->doxa-cli) (1.26.6)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\james\\anaconda3\\lib\\site-packages (from requests~=2.26.0->doxa-cli) (2.10)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\james\\anaconda3\\lib\\site-packages (from typer[all]>=0.9.0->doxa-cli) (8.0.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\james\\anaconda3\\lib\\site-packages (from typer[all]>=0.9.0->doxa-cli) (4.3.0)\n",
            "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from typer[all]>=0.9.0->doxa-cli) (1.5.4)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from typer[all]>=0.9.0->doxa-cli) (13.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from rich<14.0.0,>=10.11.0->typer[all]>=0.9.0->doxa-cli) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from rich<14.0.0,>=10.11.0->typer[all]>=0.9.0->doxa-cli) (2.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\james\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]>=0.9.0->doxa-cli) (0.1.2)\n",
            "Installing collected packages: requests, doxa-cli\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: doxa-cli\n",
            "    Found existing installation: doxa-cli 0.1.5\n",
            "    Uninstalling doxa-cli-0.1.5:\n",
            "      Successfully uninstalled doxa-cli-0.1.5\n",
            "Successfully installed doxa-cli-0.1.7 requests-2.26.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\james\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\james\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\james\\anaconda3\\lib\\site-packages)\n",
            "    WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\james\\anaconda3\\lib\\site-packages)\n",
            "    WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\james\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\james\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\james\\anaconda3\\lib\\site-packages)\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "anaconda-project 0.11.1 requires ruamel-yaml, which is not installed.\n",
            "translate-json 0.0.2 requires certifi==2021.5.30, but you have certifi 2023.5.7 which is incompatible.\n",
            "translate-json 0.0.2 requires idna==3.2; python_version >= \"3\", but you have idna 2.10 which is incompatible.\n",
            "osmnx 1.9.1 requires requests>=2.27, but you have requests 2.26.0 which is incompatible.\n",
            "conda-repo-cli 1.0.20 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
            "conda-repo-cli 1.0.20 requires nbformat==5.4.0, but you have nbformat 5.5.0 which is incompatible.\n",
            "conda-repo-cli 1.0.20 requires requests==2.28.1, but you have requests 2.26.0 which is incompatible.\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\james\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\james\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\james\\anaconda3\\lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "#%pip install numpy matplotlib zarr xarray ipykernel gcsfs fsspec dask cartopy ocf-blosc2 torchinfo\n",
        "#%pip install -U doxa-cli"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6ExjmoPXoLU"
      },
      "source": [
        "## Importing packages\n",
        "\n",
        "Here, we import a number of packages we will need to train our first model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pvlib\n",
            "  Downloading pvlib-0.10.4-py3-none-any.whl (29.5 MB)\n",
            "     --------------------------------------- 29.5/29.5 MB 10.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: requests in c:\\users\\james\\anaconda3\\lib\\site-packages (from pvlib) (2.31.0)\n",
            "Requirement already satisfied: pytz in c:\\users\\james\\anaconda3\\lib\\site-packages (from pvlib) (2022.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\james\\anaconda3\\lib\\site-packages (from pvlib) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from pvlib) (1.13.0)\n",
            "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from pvlib) (2.2.1)\n",
            "Requirement already satisfied: h5py in c:\\users\\james\\anaconda3\\lib\\site-packages (from pvlib) (3.10.0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\james\\anaconda3\\lib\\site-packages (from pandas>=1.3.0->pvlib) (2024.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\james\\anaconda3\\lib\\site-packages (from pandas>=1.3.0->pvlib) (2.8.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\james\\anaconda3\\lib\\site-packages (from requests->pvlib) (1.26.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\james\\anaconda3\\lib\\site-packages (from requests->pvlib) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\james\\anaconda3\\lib\\site-packages (from requests->pvlib) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\james\\anaconda3\\lib\\site-packages (from requests->pvlib) (2023.5.7)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\james\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->pvlib) (1.16.0)\n",
            "Installing collected packages: pvlib\n",
            "Successfully installed pvlib-0.10.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\james\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\james\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\james\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\james\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\james\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\james\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\james\\anaconda3\\lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "!pip install pvlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3F_1sE0rXoLU"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\james\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
            "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
            "c:\\Users\\james\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
            "  from pandas.core import (\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from datetime import datetime, time, timedelta\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import xarray as xr\n",
        "from ocf_blosc2 import Blosc2\n",
        "from torch.utils.data import DataLoader, IterableDataset\n",
        "from torchinfo import summary\n",
        "import json\n",
        "import geopandas as gpd\n",
        "import seaborn as sns\n",
        "from scipy.ndimage import zoom\n",
        "import numpy as np\n",
        "import h5py\n",
        "import pvlib \n",
        "import math\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (20, 12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run this block to install all data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRDvMchFXoLU",
        "outputId": "1ff0eb44-3f42-471b-8af2-3a9fb4f32ded"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "device\n",
        "if not os.path.exists(\"submission\"):\n",
        "     os.makedirs(\"submission\", exist_ok=True)\n",
        "     #Installing locally means you do not need to rerun this each time you restart the notebook\n",
        "     !curl -L https://raw.githubusercontent.com/climatehackai/getting-started-2023/main/submission/competition.py --output submission/competition.py\n",
        "     !curl -L https://raw.githubusercontent.com/climatehackai/getting-started-2023/main/submission/doxa.yaml --output submission/doxa.yaml\n",
        "     !curl -L https://raw.githubusercontent.com/climatehackai/getting-started-2023/main/submission/model.py --output submission/model.py\n",
        "     !curl -L https://raw.githubusercontent.com/climatehackai/getting-started-2023/main/submission/run.py --output submission/run.py\n",
        "     !curl -L https://raw.githubusercontent.com/climatehackai/getting-started-2023/main/indices.json --output indices.json\n",
        "if not os.path.exists(\"data\"):\n",
        "    os.makedirs(\"data/pv/2020\", exist_ok=True)\n",
        "    os.makedirs(\"data/satellite-hrv/2020\", exist_ok=True)\n",
        "\n",
        "    !curl -L https://huggingface.co/datasets/climatehackai/climatehackai-2023/resolve/main/pv/metadata.csv --output data/pv/metadata.csv\n",
        "    !curl -L https://huggingface.co/datasets/climatehackai/climatehackai-2023/resolve/main/pv/2020/7.parquet --output data/pv/2020/7.parquet\n",
        "    !curl -L https://huggingface.co/datasets/climatehackai/climatehackai-2023/resolve/main/satellite-hrv/2020/7.zarr.zip --output data/satellite-hrv/2020/7.zarr.zip\n",
        "pv = pd.read_parquet(\"data/pv/2020/7.parquet\").drop(\"generation_wh\", axis=1)\n",
        "#The parquet data here is similar to a dataframe. The \"power\" is the column with the other data types being indexes. The data is shaped with each timestamp being its own sub frame with the sites having their corresponding power (I think this is the % of their total possible yield).  \n",
        "hrv = xr.open_dataset(\n",
        "    \"data/satellite-hrv/2020/7.zarr.zip\", engine=\"zarr\", chunks=\"auto\"\n",
        ")\n",
        "#The way that this works is that it stores the image as a vector. The vectors are stored as an array of vectors. These then have a timestamp, as we only have one channel the array is a 1D set of vectors with the dimension being time. Read this to help you understand how this is being stored https://tutorial.xarray.dev/fundamentals/01_datastructures.html\n",
        "# To access I have included some examples below\n",
        "#The float value (float16-float64) shows the precision with which data is stored. Later on it is important to make sure that when you are feeding in data into the model that the float type matches between data types, this currently is not a problem when only using the HRV data. I am not yet sure if this will be a problem when using the NWP data.\n",
        "with open(\"indices.json\") as f:\n",
        "    site_locations = {\n",
        "        data_source: {\n",
        "            int(site): (int(location[0]), int(location[1]))\n",
        "            for site, location in locations.items()\n",
        "        }\n",
        "        for data_source, locations in json.load(f).items()\n",
        "    }\n",
        "if not os.path.exists(\"data\"):\n",
        "    os.makedirs(\"data/pv/2020\", exist_ok=True)\n",
        "    os.makedirs(\"data/satellite-hrv/2020\", exist_ok=True)\n",
        "\n",
        "    !curl -L https://huggingface.co/datasets/climatehackai/climatehackai-2023/resolve/main/pv/metadata.csv --output data/pv/metadata.csv\n",
        "    !curl -L https://huggingface.co/datasets/climatehackai/climatehackai-2023/resolve/main/pv/2020/7.parquet --output data/pv/2020/7.parquet\n",
        "    !curl -L https://huggingface.co/datasets/climatehackai/climatehackai-2023/resolve/main/satellite-hrv/2020/7.zarr.zip --output data/satellite-hrv/2020/7.zarr.zip "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
              "<defs>\n",
              "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
              "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
              "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
              "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
              "</symbol>\n",
              "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
              "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
              "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
              "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
              "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
              "</symbol>\n",
              "</defs>\n",
              "</svg>\n",
              "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
              " *\n",
              " */\n",
              "\n",
              ":root {\n",
              "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
              "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
              "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
              "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
              "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
              "  --xr-background-color: var(--jp-layout-color0, white);\n",
              "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
              "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
              "}\n",
              "\n",
              "html[theme=dark],\n",
              "body.vscode-dark {\n",
              "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
              "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
              "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
              "  --xr-border-color: #1F1F1F;\n",
              "  --xr-disabled-color: #515151;\n",
              "  --xr-background-color: #111111;\n",
              "  --xr-background-color-row-even: #111111;\n",
              "  --xr-background-color-row-odd: #313131;\n",
              "}\n",
              "\n",
              ".xr-wrap {\n",
              "  display: block;\n",
              "  min-width: 300px;\n",
              "  max-width: 700px;\n",
              "}\n",
              "\n",
              ".xr-text-repr-fallback {\n",
              "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
              "  display: none;\n",
              "}\n",
              "\n",
              ".xr-header {\n",
              "  padding-top: 6px;\n",
              "  padding-bottom: 6px;\n",
              "  margin-bottom: 4px;\n",
              "  border-bottom: solid 1px var(--xr-border-color);\n",
              "}\n",
              "\n",
              ".xr-header > div,\n",
              ".xr-header > ul {\n",
              "  display: inline;\n",
              "  margin-top: 0;\n",
              "  margin-bottom: 0;\n",
              "}\n",
              "\n",
              ".xr-obj-type,\n",
              ".xr-array-name {\n",
              "  margin-left: 2px;\n",
              "  margin-right: 10px;\n",
              "}\n",
              "\n",
              ".xr-obj-type {\n",
              "  color: var(--xr-font-color2);\n",
              "}\n",
              "\n",
              ".xr-sections {\n",
              "  padding-left: 0 !important;\n",
              "  display: grid;\n",
              "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
              "}\n",
              "\n",
              ".xr-section-item {\n",
              "  display: contents;\n",
              "}\n",
              "\n",
              ".xr-section-item input {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              ".xr-section-item input + label {\n",
              "  color: var(--xr-disabled-color);\n",
              "}\n",
              "\n",
              ".xr-section-item input:enabled + label {\n",
              "  cursor: pointer;\n",
              "  color: var(--xr-font-color2);\n",
              "}\n",
              "\n",
              ".xr-section-item input:enabled + label:hover {\n",
              "  color: var(--xr-font-color0);\n",
              "}\n",
              "\n",
              ".xr-section-summary {\n",
              "  grid-column: 1;\n",
              "  color: var(--xr-font-color2);\n",
              "  font-weight: 500;\n",
              "}\n",
              "\n",
              ".xr-section-summary > span {\n",
              "  display: inline-block;\n",
              "  padding-left: 0.5em;\n",
              "}\n",
              "\n",
              ".xr-section-summary-in:disabled + label {\n",
              "  color: var(--xr-font-color2);\n",
              "}\n",
              "\n",
              ".xr-section-summary-in + label:before {\n",
              "  display: inline-block;\n",
              "  content: '►';\n",
              "  font-size: 11px;\n",
              "  width: 15px;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              ".xr-section-summary-in:disabled + label:before {\n",
              "  color: var(--xr-disabled-color);\n",
              "}\n",
              "\n",
              ".xr-section-summary-in:checked + label:before {\n",
              "  content: '▼';\n",
              "}\n",
              "\n",
              ".xr-section-summary-in:checked + label > span {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              ".xr-section-summary,\n",
              ".xr-section-inline-details {\n",
              "  padding-top: 4px;\n",
              "  padding-bottom: 4px;\n",
              "}\n",
              "\n",
              ".xr-section-inline-details {\n",
              "  grid-column: 2 / -1;\n",
              "}\n",
              "\n",
              ".xr-section-details {\n",
              "  display: none;\n",
              "  grid-column: 1 / -1;\n",
              "  margin-bottom: 5px;\n",
              "}\n",
              "\n",
              ".xr-section-summary-in:checked ~ .xr-section-details {\n",
              "  display: contents;\n",
              "}\n",
              "\n",
              ".xr-array-wrap {\n",
              "  grid-column: 1 / -1;\n",
              "  display: grid;\n",
              "  grid-template-columns: 20px auto;\n",
              "}\n",
              "\n",
              ".xr-array-wrap > label {\n",
              "  grid-column: 1;\n",
              "  vertical-align: top;\n",
              "}\n",
              "\n",
              ".xr-preview {\n",
              "  color: var(--xr-font-color3);\n",
              "}\n",
              "\n",
              ".xr-array-preview,\n",
              ".xr-array-data {\n",
              "  padding: 0 5px !important;\n",
              "  grid-column: 2;\n",
              "}\n",
              "\n",
              ".xr-array-data,\n",
              ".xr-array-in:checked ~ .xr-array-preview {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              ".xr-array-in:checked ~ .xr-array-data,\n",
              ".xr-array-preview {\n",
              "  display: inline-block;\n",
              "}\n",
              "\n",
              ".xr-dim-list {\n",
              "  display: inline-block !important;\n",
              "  list-style: none;\n",
              "  padding: 0 !important;\n",
              "  margin: 0;\n",
              "}\n",
              "\n",
              ".xr-dim-list li {\n",
              "  display: inline-block;\n",
              "  padding: 0;\n",
              "  margin: 0;\n",
              "}\n",
              "\n",
              ".xr-dim-list:before {\n",
              "  content: '(';\n",
              "}\n",
              "\n",
              ".xr-dim-list:after {\n",
              "  content: ')';\n",
              "}\n",
              "\n",
              ".xr-dim-list li:not(:last-child):after {\n",
              "  content: ',';\n",
              "  padding-right: 5px;\n",
              "}\n",
              "\n",
              ".xr-has-index {\n",
              "  font-weight: bold;\n",
              "}\n",
              "\n",
              ".xr-var-list,\n",
              ".xr-var-item {\n",
              "  display: contents;\n",
              "}\n",
              "\n",
              ".xr-var-item > div,\n",
              ".xr-var-item label,\n",
              ".xr-var-item > .xr-var-name span {\n",
              "  background-color: var(--xr-background-color-row-even);\n",
              "  margin-bottom: 0;\n",
              "}\n",
              "\n",
              ".xr-var-item > .xr-var-name:hover span {\n",
              "  padding-right: 5px;\n",
              "}\n",
              "\n",
              ".xr-var-list > li:nth-child(odd) > div,\n",
              ".xr-var-list > li:nth-child(odd) > label,\n",
              ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
              "  background-color: var(--xr-background-color-row-odd);\n",
              "}\n",
              "\n",
              ".xr-var-name {\n",
              "  grid-column: 1;\n",
              "}\n",
              "\n",
              ".xr-var-dims {\n",
              "  grid-column: 2;\n",
              "}\n",
              "\n",
              ".xr-var-dtype {\n",
              "  grid-column: 3;\n",
              "  text-align: right;\n",
              "  color: var(--xr-font-color2);\n",
              "}\n",
              "\n",
              ".xr-var-preview {\n",
              "  grid-column: 4;\n",
              "}\n",
              "\n",
              ".xr-var-name,\n",
              ".xr-var-dims,\n",
              ".xr-var-dtype,\n",
              ".xr-preview,\n",
              ".xr-attrs dt {\n",
              "  white-space: nowrap;\n",
              "  overflow: hidden;\n",
              "  text-overflow: ellipsis;\n",
              "  padding-right: 10px;\n",
              "}\n",
              "\n",
              ".xr-var-name:hover,\n",
              ".xr-var-dims:hover,\n",
              ".xr-var-dtype:hover,\n",
              ".xr-attrs dt:hover {\n",
              "  overflow: visible;\n",
              "  width: auto;\n",
              "  z-index: 1;\n",
              "}\n",
              "\n",
              ".xr-var-attrs,\n",
              ".xr-var-data {\n",
              "  display: none;\n",
              "  background-color: var(--xr-background-color) !important;\n",
              "  padding-bottom: 5px !important;\n",
              "}\n",
              "\n",
              ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
              ".xr-var-data-in:checked ~ .xr-var-data {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              ".xr-var-data > table {\n",
              "  float: right;\n",
              "}\n",
              "\n",
              ".xr-var-name span,\n",
              ".xr-var-data,\n",
              ".xr-attrs {\n",
              "  padding-left: 25px !important;\n",
              "}\n",
              "\n",
              ".xr-attrs,\n",
              ".xr-var-attrs,\n",
              ".xr-var-data {\n",
              "  grid-column: 1 / -1;\n",
              "}\n",
              "\n",
              "dl.xr-attrs {\n",
              "  padding: 0;\n",
              "  margin: 0;\n",
              "  display: grid;\n",
              "  grid-template-columns: 125px auto;\n",
              "}\n",
              "\n",
              ".xr-attrs dt,\n",
              ".xr-attrs dd {\n",
              "  padding: 0;\n",
              "  margin: 0;\n",
              "  float: left;\n",
              "  padding-right: 10px;\n",
              "  width: auto;\n",
              "}\n",
              "\n",
              ".xr-attrs dt {\n",
              "  font-weight: normal;\n",
              "  grid-column: 1;\n",
              "}\n",
              "\n",
              ".xr-attrs dt:hover span {\n",
              "  display: inline-block;\n",
              "  background: var(--xr-background-color);\n",
              "  padding-right: 10px;\n",
              "}\n",
              "\n",
              ".xr-attrs dd {\n",
              "  grid-column: 2;\n",
              "  white-space: pre-wrap;\n",
              "  word-break: break-all;\n",
              "}\n",
              "\n",
              ".xr-icon-database,\n",
              ".xr-icon-file-text2 {\n",
              "  display: inline-block;\n",
              "  vertical-align: middle;\n",
              "  width: 1em;\n",
              "  height: 1.5em !important;\n",
              "  stroke-width: 0;\n",
              "  stroke: currentColor;\n",
              "  fill: currentColor;\n",
              "}\n",
              "</style><pre class='xr-text-repr-fallback'>&lt;xarray.DataArray &#x27;data&#x27; (time: 6721, y_geostationary: 592, x_geostationary: 684, channel: 1)&gt;\n",
              "dask.array&lt;open_dataset-138c76fe526a542f7b6c787fe2f7b4d8data, shape=(6721, 592, 684, 1), dtype=float16, chunksize=(143, 592, 684, 1), chunktype=numpy.ndarray&gt;\n",
              "Coordinates:\n",
              "  * channel          (channel) &lt;U3 &#x27;HRV&#x27;\n",
              "  * time             (time) datetime64[ns] 2020-07-01T04:00:00 ... 2020-07-31...\n",
              "  * x_geostationary  (x_geostationary) float64 -1.089e+06 ... -4.061e+05\n",
              "  * y_geostationary  (y_geostationary) float64 4.449e+06 4.45e+06 ... 5.04e+06\n",
              "Attributes:\n",
              "    HRV__satpy_id:                              !!python/object/apply:satpy.d...\n",
              "    HRV_ancillary_variables:                    []\n",
              "    HRV_area:                                   msg_seviri_rss_1km:\\n  descri...\n",
              "    HRV_calibration:                            reflectance\n",
              "    HRV_end_time:                               2020-01-01T00:00:07.676580\n",
              "    HRV_georef_offset_corrected:                True\n",
              "    HRV_modifiers:                              []\n",
              "    HRV_name:                                   HRV\n",
              "    HRV_orbital_parameters:                     projection_altitude: 35785831...\n",
              "    HRV_platform_name:                          Meteosat-10\n",
              "    HRV_reader:                                 seviri_l1b_native\n",
              "    HRV_resolution:                             1000.134348869\n",
              "    HRV_sensor:                                 seviri\n",
              "    HRV_standard_name:                          toa_bidirectional_reflectance\n",
              "    HRV_start_time:                             2019-12-31T23:55:07.772388\n",
              "    HRV_sun_earth_distance_correction_applied:  True\n",
              "    HRV_sun_earth_distance_correction_factor:   0.9666341924425861\n",
              "    HRV_units:                                  %\n",
              "    HRV_wavelength:                             [0.5, 0.7, 0.9, &#x27;µm&#x27;]\n",
              "    _satpy_id:                                  !!python/object/apply:satpy.d...\n",
              "    ancillary_variables:                        []\n",
              "    area:                                       msg_seviri_rss_1km:\\n  descri...\n",
              "    calibration:                                reflectance\n",
              "    end_time:                                   2020-01-01T00:00:00\n",
              "    georef_offset_corrected:                    True\n",
              "    modifiers:                                  []\n",
              "    name:                                       HRV\n",
              "    orbital_parameters:                         projection_altitude: 35785831...\n",
              "    platform_name:                              Meteosat-10\n",
              "    reader:                                     seviri_l1b_native\n",
              "    resolution:                                 1000.134348869\n",
              "    sensor:                                     seviri\n",
              "    standard_name:                              toa_bidirectional_reflectance\n",
              "    start_time:                                 2019-12-31T23:55:07.772388\n",
              "    sun_earth_distance_correction_applied:      True\n",
              "    sun_earth_distance_correction_factor:       0.9666341924425861\n",
              "    units:                                      %\n",
              "    wavelength:                                 [0.5, 0.7, 0.9, &#x27;µm&#x27;]</pre><div class='xr-wrap' hidden><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'>'data'</div><ul class='xr-dim-list'><li><span class='xr-has-index'>time</span>: 6721</li><li><span class='xr-has-index'>y_geostationary</span>: 592</li><li><span class='xr-has-index'>x_geostationary</span>: 684</li><li><span class='xr-has-index'>channel</span>: 1</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-2176f371-c20e-4cc1-8f41-ab329d5ad5ec' class='xr-array-in' type='checkbox' checked><label for='section-2176f371-c20e-4cc1-8f41-ab329d5ad5ec' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>dask.array&lt;chunksize=(143, 592, 684, 1), meta=np.ndarray&gt;</span></div><div class='xr-array-data'><table>\n",
              "    <tr>\n",
              "        <td>\n",
              "            <table>\n",
              "                <thead>\n",
              "                    <tr>\n",
              "                        <td> </td>\n",
              "                        <th> Array </th>\n",
              "                        <th> Chunk </th>\n",
              "                    </tr>\n",
              "                </thead>\n",
              "                <tbody>\n",
              "                    \n",
              "                    <tr>\n",
              "                        <th> Bytes </th>\n",
              "                        <td> 5.07 GiB </td>\n",
              "                        <td> 110.44 MiB </td>\n",
              "                    </tr>\n",
              "                    \n",
              "                    <tr>\n",
              "                        <th> Shape </th>\n",
              "                        <td> (6721, 592, 684, 1) </td>\n",
              "                        <td> (143, 592, 684, 1) </td>\n",
              "                    </tr>\n",
              "                    <tr>\n",
              "                        <th> Count </th>\n",
              "                        <td> 48 Tasks </td>\n",
              "                        <td> 47 Chunks </td>\n",
              "                    </tr>\n",
              "                    <tr>\n",
              "                    <th> Type </th>\n",
              "                    <td> float16 </td>\n",
              "                    <td> numpy.ndarray </td>\n",
              "                    </tr>\n",
              "                </tbody>\n",
              "            </table>\n",
              "        </td>\n",
              "        <td>\n",
              "        <svg width=\"477\" height=\"110\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
              "\n",
              "  <!-- Horizontal lines -->\n",
              "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
              "  <line x1=\"0\" y1=\"25\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
              "\n",
              "  <!-- Vertical lines -->\n",
              "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"25\" style=\"stroke-width:2\" />\n",
              "  <line x1=\"2\" y1=\"0\" x2=\"2\" y2=\"25\" />\n",
              "  <line x1=\"5\" y1=\"0\" x2=\"5\" y2=\"25\" />\n",
              "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"25\" />\n",
              "  <line x1=\"12\" y1=\"0\" x2=\"12\" y2=\"25\" />\n",
              "  <line x1=\"17\" y1=\"0\" x2=\"17\" y2=\"25\" />\n",
              "  <line x1=\"20\" y1=\"0\" x2=\"20\" y2=\"25\" />\n",
              "  <line x1=\"25\" y1=\"0\" x2=\"25\" y2=\"25\" />\n",
              "  <line x1=\"28\" y1=\"0\" x2=\"28\" y2=\"25\" />\n",
              "  <line x1=\"33\" y1=\"0\" x2=\"33\" y2=\"25\" />\n",
              "  <line x1=\"35\" y1=\"0\" x2=\"35\" y2=\"25\" />\n",
              "  <line x1=\"40\" y1=\"0\" x2=\"40\" y2=\"25\" />\n",
              "  <line x1=\"43\" y1=\"0\" x2=\"43\" y2=\"25\" />\n",
              "  <line x1=\"48\" y1=\"0\" x2=\"48\" y2=\"25\" />\n",
              "  <line x1=\"51\" y1=\"0\" x2=\"51\" y2=\"25\" />\n",
              "  <line x1=\"56\" y1=\"0\" x2=\"56\" y2=\"25\" />\n",
              "  <line x1=\"58\" y1=\"0\" x2=\"58\" y2=\"25\" />\n",
              "  <line x1=\"61\" y1=\"0\" x2=\"61\" y2=\"25\" />\n",
              "  <line x1=\"66\" y1=\"0\" x2=\"66\" y2=\"25\" />\n",
              "  <line x1=\"68\" y1=\"0\" x2=\"68\" y2=\"25\" />\n",
              "  <line x1=\"74\" y1=\"0\" x2=\"74\" y2=\"25\" />\n",
              "  <line x1=\"76\" y1=\"0\" x2=\"76\" y2=\"25\" />\n",
              "  <line x1=\"81\" y1=\"0\" x2=\"81\" y2=\"25\" />\n",
              "  <line x1=\"84\" y1=\"0\" x2=\"84\" y2=\"25\" />\n",
              "  <line x1=\"89\" y1=\"0\" x2=\"89\" y2=\"25\" />\n",
              "  <line x1=\"91\" y1=\"0\" x2=\"91\" y2=\"25\" />\n",
              "  <line x1=\"97\" y1=\"0\" x2=\"97\" y2=\"25\" />\n",
              "  <line x1=\"99\" y1=\"0\" x2=\"99\" y2=\"25\" />\n",
              "  <line x1=\"104\" y1=\"0\" x2=\"104\" y2=\"25\" />\n",
              "  <line x1=\"107\" y1=\"0\" x2=\"107\" y2=\"25\" />\n",
              "  <line x1=\"112\" y1=\"0\" x2=\"112\" y2=\"25\" />\n",
              "  <line x1=\"114\" y1=\"0\" x2=\"114\" y2=\"25\" />\n",
              "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
              "\n",
              "  <!-- Colored Rectangle -->\n",
              "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,25.412616514582485 0.0,25.412616514582485\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
              "\n",
              "  <!-- Text -->\n",
              "  <text x=\"60.000000\" y=\"45.412617\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >6721</text>\n",
              "  <text x=\"140.000000\" y=\"12.706308\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,12.706308)\">1</text>\n",
              "\n",
              "\n",
              "  <!-- Horizontal lines -->\n",
              "  <line x1=\"190\" y1=\"0\" x2=\"212\" y2=\"22\" style=\"stroke-width:2\" />\n",
              "  <line x1=\"190\" y1=\"38\" x2=\"212\" y2=\"60\" style=\"stroke-width:2\" />\n",
              "\n",
              "  <!-- Vertical lines -->\n",
              "  <line x1=\"190\" y1=\"0\" x2=\"190\" y2=\"38\" style=\"stroke-width:2\" />\n",
              "  <line x1=\"212\" y1=\"22\" x2=\"212\" y2=\"60\" style=\"stroke-width:2\" />\n",
              "\n",
              "  <!-- Colored Rectangle -->\n",
              "  <polygon points=\"190.0,0.0 212.28367595155123,22.28367595155124 212.28367595155123,60.97757840090871 190.0,38.69390244935747\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
              "\n",
              "  <!-- Horizontal lines -->\n",
              "  <line x1=\"190\" y1=\"0\" x2=\"215\" y2=\"0\" style=\"stroke-width:2\" />\n",
              "  <line x1=\"212\" y1=\"22\" x2=\"237\" y2=\"22\" style=\"stroke-width:2\" />\n",
              "\n",
              "  <!-- Vertical lines -->\n",
              "  <line x1=\"190\" y1=\"0\" x2=\"212\" y2=\"22\" style=\"stroke-width:2\" />\n",
              "  <line x1=\"215\" y1=\"0\" x2=\"237\" y2=\"22\" style=\"stroke-width:2\" />\n",
              "\n",
              "  <!-- Colored Rectangle -->\n",
              "  <polygon points=\"190.0,0.0 215.41261651458248,0.0 237.6962924661337,22.28367595155124 212.28367595155123,22.28367595155124\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
              "\n",
              "  <!-- Horizontal lines -->\n",
              "  <line x1=\"212\" y1=\"22\" x2=\"237\" y2=\"22\" style=\"stroke-width:2\" />\n",
              "  <line x1=\"212\" y1=\"60\" x2=\"237\" y2=\"60\" style=\"stroke-width:2\" />\n",
              "\n",
              "  <!-- Vertical lines -->\n",
              "  <line x1=\"212\" y1=\"22\" x2=\"212\" y2=\"60\" style=\"stroke-width:2\" />\n",
              "  <line x1=\"237\" y1=\"22\" x2=\"237\" y2=\"60\" style=\"stroke-width:2\" />\n",
              "\n",
              "  <!-- Colored Rectangle -->\n",
              "  <polygon points=\"212.28367595155123,22.28367595155124 237.6962924661337,22.28367595155124 237.6962924661337,60.97757840090871 212.28367595155123,60.97757840090871\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
              "\n",
              "  <!-- Text -->\n",
              "  <text x=\"224.989984\" y=\"80.977578\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1</text>\n",
              "  <text x=\"257.696292\" y=\"41.630627\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,257.696292,41.630627)\">684</text>\n",
              "  <text x=\"191.141838\" y=\"69.835740\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,191.141838,69.835740)\">592</text>\n",
              "</svg>\n",
              "        </td>\n",
              "    </tr>\n",
              "</table></div></div></li><li class='xr-section-item'><input id='section-c60b73e7-4511-4e44-b8ef-22836c37ad47' class='xr-section-summary-in' type='checkbox'  checked><label for='section-c60b73e7-4511-4e44-b8ef-22836c37ad47' class='xr-section-summary' >Coordinates: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>channel</span></div><div class='xr-var-dims'>(channel)</div><div class='xr-var-dtype'>&lt;U3</div><div class='xr-var-preview xr-preview'>&#x27;HRV&#x27;</div><input id='attrs-e8bd8807-b073-48cf-a141-6253a79e517a' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-e8bd8807-b073-48cf-a141-6253a79e517a' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-6938c327-5c5f-48e2-a07d-498999dde04f' class='xr-var-data-in' type='checkbox'><label for='data-6938c327-5c5f-48e2-a07d-498999dde04f' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;HRV&#x27;], dtype=&#x27;&lt;U3&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>2020-07-01T04:00:00 ... 2020-07-...</div><input id='attrs-106ae791-e2e7-4e67-b978-478fa725b72c' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-106ae791-e2e7-4e67-b978-478fa725b72c' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-5b06bfd7-5808-415d-95bf-3772ea4b40ee' class='xr-var-data-in' type='checkbox'><label for='data-5b06bfd7-5808-415d-95bf-3772ea4b40ee' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;2020-07-01T04:00:00.000000000&#x27;, &#x27;2020-07-01T04:05:00.000000000&#x27;,\n",
              "       &#x27;2020-07-01T04:10:00.000000000&#x27;, ..., &#x27;2020-07-31T21:50:00.000000000&#x27;,\n",
              "       &#x27;2020-07-31T21:55:00.000000000&#x27;, &#x27;2020-07-31T22:00:00.000000000&#x27;],\n",
              "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>x_geostationary</span></div><div class='xr-var-dims'>(x_geostationary)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>-1.089e+06 ... -4.061e+05</div><input id='attrs-4e8648c7-4b42-426b-ae29-5242638039ae' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-4e8648c7-4b42-426b-ae29-5242638039ae' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-2a2a8473-a021-4723-bfad-05c6d87dfe73' class='xr-var-data-in' type='checkbox'><label for='data-2a2a8473-a021-4723-bfad-05c6d87dfe73' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([-1089146.305919, -1088146.17157 , -1087146.037221, ...,  -408054.814339,\n",
              "        -407054.67999 ,  -406054.545641])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>y_geostationary</span></div><div class='xr-var-dims'>(y_geostationary)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>4.449e+06 4.45e+06 ... 5.04e+06</div><input id='attrs-d285c108-9de2-405c-89c1-48e27db2ec84' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-d285c108-9de2-405c-89c1-48e27db2ec84' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-76e4653b-8d6e-47d9-a515-873cb3f7f9ee' class='xr-var-data-in' type='checkbox'><label for='data-76e4653b-8d6e-47d9-a515-873cb3f7f9ee' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([4448597.583771, 4449597.71812 , 4450597.852468, ..., 5037676.715255,\n",
              "       5038676.849604, 5039676.983953])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-6ad799fb-6f27-4341-a992-eb4bf72d3d1f' class='xr-section-summary-in' type='checkbox'  ><label for='section-6ad799fb-6f27-4341-a992-eb4bf72d3d1f' class='xr-section-summary' >Attributes: <span>(38)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>HRV__satpy_id :</span></dt><dd>!!python/object/apply:satpy.dataset.dataid._unpickle\n",
              "- calibration:\n",
              "    enum:\n",
              "    - reflectance\n",
              "    - brightness_temperature\n",
              "    - radiance\n",
              "    - counts\n",
              "    transitive: true\n",
              "  modifiers:\n",
              "    default: !!python/object/new:satpy.dataset.dataid.ModifierTuple\n",
              "    - !!python/tuple []\n",
              "    type: !!python/name:satpy.dataset.dataid.ModifierTuple &#x27;&#x27;\n",
              "  name:\n",
              "    required: true\n",
              "  resolution:\n",
              "    transitive: false\n",
              "  wavelength:\n",
              "    type: !!python/name:satpy.dataset.dataid.WavelengthRange &#x27;&#x27;\n",
              "- calibration: reflectance\n",
              "  modifiers: !!python/object/new:satpy.dataset.dataid.ModifierTuple\n",
              "  - !!python/tuple []\n",
              "  name: HRV\n",
              "  resolution: 1000.134348869\n",
              "  wavelength: !!python/object/new:satpy.dataset.dataid.WavelengthRange\n",
              "  - 0.5\n",
              "  - 0.7\n",
              "  - 0.9\n",
              "  - &quot;\\xB5m&quot;\n",
              "</dd><dt><span>HRV_ancillary_variables :</span></dt><dd>[]</dd><dt><span>HRV_area :</span></dt><dd>msg_seviri_rss_1km:\n",
              "  description: MSG SEVIRI Rapid Scanning Service area definition with 1 km resolution\n",
              "  projection:\n",
              "    proj: geos\n",
              "    lon_0: 9.5\n",
              "    h: 35785831\n",
              "    x_0: 0\n",
              "    y_0: 0\n",
              "    a: 6378169\n",
              "    rf: 295.488065897014\n",
              "    no_defs: null\n",
              "    type: crs\n",
              "  shape:\n",
              "    height: 4176\n",
              "    width: 5568\n",
              "  area_extent:\n",
              "    lower_left_xy: [2847882.5584053993, 5571248.390376568]\n",
              "    upper_right_xy: [-2720865.496098995, 1394687.349498272]\n",
              "    units: m\n",
              "</dd><dt><span>HRV_calibration :</span></dt><dd>reflectance</dd><dt><span>HRV_end_time :</span></dt><dd>2020-01-01T00:00:07.676580</dd><dt><span>HRV_georef_offset_corrected :</span></dt><dd>True</dd><dt><span>HRV_modifiers :</span></dt><dd>[]</dd><dt><span>HRV_name :</span></dt><dd>HRV</dd><dt><span>HRV_orbital_parameters :</span></dt><dd>projection_altitude: 35785831.0\n",
              "projection_latitude: 0.0\n",
              "projection_longitude: 9.5\n",
              "satellite_actual_altitude: 35785194.01716657\n",
              "satellite_actual_latitude: 0.9667690739053058\n",
              "satellite_actual_longitude: 9.345990336803867\n",
              "satellite_nominal_latitude: 0.0\n",
              "satellite_nominal_longitude: 9.5\n",
              "</dd><dt><span>HRV_platform_name :</span></dt><dd>Meteosat-10</dd><dt><span>HRV_reader :</span></dt><dd>seviri_l1b_native</dd><dt><span>HRV_resolution :</span></dt><dd>1000.134348869</dd><dt><span>HRV_sensor :</span></dt><dd>seviri</dd><dt><span>HRV_standard_name :</span></dt><dd>toa_bidirectional_reflectance</dd><dt><span>HRV_start_time :</span></dt><dd>2019-12-31T23:55:07.772388</dd><dt><span>HRV_sun_earth_distance_correction_applied :</span></dt><dd>True</dd><dt><span>HRV_sun_earth_distance_correction_factor :</span></dt><dd>0.9666341924425861</dd><dt><span>HRV_units :</span></dt><dd>%</dd><dt><span>HRV_wavelength :</span></dt><dd>[0.5, 0.7, 0.9, &#x27;µm&#x27;]</dd><dt><span>_satpy_id :</span></dt><dd>!!python/object/apply:satpy.dataset.dataid._unpickle\n",
              "- calibration:\n",
              "    enum:\n",
              "    - reflectance\n",
              "    - brightness_temperature\n",
              "    - radiance\n",
              "    - counts\n",
              "    transitive: true\n",
              "  modifiers:\n",
              "    default: !!python/object/new:satpy.dataset.dataid.ModifierTuple\n",
              "    - !!python/tuple []\n",
              "    type: !!python/name:satpy.dataset.dataid.ModifierTuple &#x27;&#x27;\n",
              "  name:\n",
              "    required: true\n",
              "  resolution:\n",
              "    transitive: false\n",
              "  wavelength:\n",
              "    type: !!python/name:satpy.dataset.dataid.WavelengthRange &#x27;&#x27;\n",
              "- calibration: reflectance\n",
              "  modifiers: !!python/object/new:satpy.dataset.dataid.ModifierTuple\n",
              "  - !!python/tuple []\n",
              "  name: HRV\n",
              "  resolution: 1000.134348869\n",
              "  wavelength: !!python/object/new:satpy.dataset.dataid.WavelengthRange\n",
              "  - 0.5\n",
              "  - 0.7\n",
              "  - 0.9\n",
              "  - &quot;\\xB5m&quot;\n",
              "</dd><dt><span>ancillary_variables :</span></dt><dd>[]</dd><dt><span>area :</span></dt><dd>msg_seviri_rss_1km:\n",
              "  description: MSG SEVIRI Rapid Scanning Service area definition with 1 km resolution\n",
              "  projection:\n",
              "    proj: geos\n",
              "    lon_0: 9.5\n",
              "    h: 35785831\n",
              "    x_0: 0\n",
              "    y_0: 0\n",
              "    a: 6378169\n",
              "    rf: 295.488065897014\n",
              "    no_defs: null\n",
              "    type: crs\n",
              "  shape:\n",
              "    height: 4176\n",
              "    width: 5568\n",
              "  area_extent:\n",
              "    lower_left_xy: [2847882.5584053993, 5571248.390376568]\n",
              "    upper_right_xy: [-2720865.496098995, 1394687.349498272]\n",
              "    units: m\n",
              "</dd><dt><span>calibration :</span></dt><dd>reflectance</dd><dt><span>end_time :</span></dt><dd>2020-01-01T00:00:00</dd><dt><span>georef_offset_corrected :</span></dt><dd>True</dd><dt><span>modifiers :</span></dt><dd>[]</dd><dt><span>name :</span></dt><dd>HRV</dd><dt><span>orbital_parameters :</span></dt><dd>projection_altitude: 35785831.0\n",
              "projection_latitude: 0.0\n",
              "projection_longitude: 9.5\n",
              "satellite_actual_altitude: 35785194.01716657\n",
              "satellite_actual_latitude: 0.9667690739053058\n",
              "satellite_actual_longitude: 9.345990336803867\n",
              "satellite_nominal_latitude: 0.0\n",
              "satellite_nominal_longitude: 9.5\n",
              "</dd><dt><span>platform_name :</span></dt><dd>Meteosat-10</dd><dt><span>reader :</span></dt><dd>seviri_l1b_native</dd><dt><span>resolution :</span></dt><dd>1000.134348869</dd><dt><span>sensor :</span></dt><dd>seviri</dd><dt><span>standard_name :</span></dt><dd>toa_bidirectional_reflectance</dd><dt><span>start_time :</span></dt><dd>2019-12-31T23:55:07.772388</dd><dt><span>sun_earth_distance_correction_applied :</span></dt><dd>True</dd><dt><span>sun_earth_distance_correction_factor :</span></dt><dd>0.9666341924425861</dd><dt><span>units :</span></dt><dd>%</dd><dt><span>wavelength :</span></dt><dd>[0.5, 0.7, 0.9, &#x27;µm&#x27;]</dd></dl></div></li></ul></div></div>"
            ],
            "text/plain": [
              "<xarray.DataArray 'data' (time: 6721, y_geostationary: 592, x_geostationary: 684, channel: 1)>\n",
              "dask.array<open_dataset-138c76fe526a542f7b6c787fe2f7b4d8data, shape=(6721, 592, 684, 1), dtype=float16, chunksize=(143, 592, 684, 1), chunktype=numpy.ndarray>\n",
              "Coordinates:\n",
              "  * channel          (channel) <U3 'HRV'\n",
              "  * time             (time) datetime64[ns] 2020-07-01T04:00:00 ... 2020-07-31...\n",
              "  * x_geostationary  (x_geostationary) float64 -1.089e+06 ... -4.061e+05\n",
              "  * y_geostationary  (y_geostationary) float64 4.449e+06 4.45e+06 ... 5.04e+06\n",
              "Attributes:\n",
              "    HRV__satpy_id:                              !!python/object/apply:satpy.d...\n",
              "    HRV_ancillary_variables:                    []\n",
              "    HRV_area:                                   msg_seviri_rss_1km:\\n  descri...\n",
              "    HRV_calibration:                            reflectance\n",
              "    HRV_end_time:                               2020-01-01T00:00:07.676580\n",
              "    HRV_georef_offset_corrected:                True\n",
              "    HRV_modifiers:                              []\n",
              "    HRV_name:                                   HRV\n",
              "    HRV_orbital_parameters:                     projection_altitude: 35785831...\n",
              "    HRV_platform_name:                          Meteosat-10\n",
              "    HRV_reader:                                 seviri_l1b_native\n",
              "    HRV_resolution:                             1000.134348869\n",
              "    HRV_sensor:                                 seviri\n",
              "    HRV_standard_name:                          toa_bidirectional_reflectance\n",
              "    HRV_start_time:                             2019-12-31T23:55:07.772388\n",
              "    HRV_sun_earth_distance_correction_applied:  True\n",
              "    HRV_sun_earth_distance_correction_factor:   0.9666341924425861\n",
              "    HRV_units:                                  %\n",
              "    HRV_wavelength:                             [0.5, 0.7, 0.9, 'µm']\n",
              "    _satpy_id:                                  !!python/object/apply:satpy.d...\n",
              "    ancillary_variables:                        []\n",
              "    area:                                       msg_seviri_rss_1km:\\n  descri...\n",
              "    calibration:                                reflectance\n",
              "    end_time:                                   2020-01-01T00:00:00\n",
              "    georef_offset_corrected:                    True\n",
              "    modifiers:                                  []\n",
              "    name:                                       HRV\n",
              "    orbital_parameters:                         projection_altitude: 35785831...\n",
              "    platform_name:                              Meteosat-10\n",
              "    reader:                                     seviri_l1b_native\n",
              "    resolution:                                 1000.134348869\n",
              "    sensor:                                     seviri\n",
              "    standard_name:                              toa_bidirectional_reflectance\n",
              "    start_time:                                 2019-12-31T23:55:07.772388\n",
              "    sun_earth_distance_correction_applied:      True\n",
              "    sun_earth_distance_correction_factor:       0.9666341924425861\n",
              "    units:                                      %\n",
              "    wavelength:                                 [0.5, 0.7, 0.9, 'µm']"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hrv[\"data\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## For generating the angle of solar incidence  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "#this block finds the long and lat for the sites where it is available \n",
        "pv_ss_id = pv.index.get_level_values(\"ss_id\").unique()\n",
        "pv_ss_time = pv.index.get_level_values(\"timestamp\")\n",
        "pv_meta = pd.read_csv(\"data/pv/metadata.csv\")\n",
        "pv_meta_ssid = pv_meta.ss_id\n",
        "shared_id = [x for x in pv_ss_id if x in pv_meta_ssid]\n",
        "pv_shared = pv_meta[pv_meta[\"ss_id\"].isin(shared_id)] #shared location data, only 698 of 908 sites in the pv file have long and lat for plotting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>ss_id</th>\n",
              "      <th>power</th>\n",
              "      <th>latitude_rounded</th>\n",
              "      <th>longitude_rounded</th>\n",
              "      <th>orientation</th>\n",
              "      <th>tilt</th>\n",
              "      <th>altitude</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-07-01 00:00:00+00:00</td>\n",
              "      <td>2607</td>\n",
              "      <td>0.0</td>\n",
              "      <td>52.44</td>\n",
              "      <td>-0.12</td>\n",
              "      <td>200.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-07-01 00:00:00+00:00</td>\n",
              "      <td>2626</td>\n",
              "      <td>0.0</td>\n",
              "      <td>54.99</td>\n",
              "      <td>-3.18</td>\n",
              "      <td>270.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-07-01 00:00:00+00:00</td>\n",
              "      <td>2631</td>\n",
              "      <td>0.0</td>\n",
              "      <td>51.81</td>\n",
              "      <td>-2.50</td>\n",
              "      <td>130.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-07-01 00:00:00+00:00</td>\n",
              "      <td>2657</td>\n",
              "      <td>0.0</td>\n",
              "      <td>51.49</td>\n",
              "      <td>0.36</td>\n",
              "      <td>185.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-07-01 00:00:00+00:00</td>\n",
              "      <td>2729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>51.61</td>\n",
              "      <td>-0.24</td>\n",
              "      <td>180.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6039341</th>\n",
              "      <td>2020-07-31 23:55:00+00:00</td>\n",
              "      <td>18873</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53.59</td>\n",
              "      <td>-3.04</td>\n",
              "      <td>290.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6039342</th>\n",
              "      <td>2020-07-31 23:55:00+00:00</td>\n",
              "      <td>18989</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53.55</td>\n",
              "      <td>-2.23</td>\n",
              "      <td>207.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6039343</th>\n",
              "      <td>2020-07-31 23:55:00+00:00</td>\n",
              "      <td>18990</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53.76</td>\n",
              "      <td>-1.52</td>\n",
              "      <td>180.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6039344</th>\n",
              "      <td>2020-07-31 23:55:00+00:00</td>\n",
              "      <td>22335</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53.10</td>\n",
              "      <td>-2.04</td>\n",
              "      <td>140.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6039345</th>\n",
              "      <td>2020-07-31 23:55:00+00:00</td>\n",
              "      <td>23083</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53.06</td>\n",
              "      <td>-2.98</td>\n",
              "      <td>120.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6039346 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                        timestamp  ss_id  power  latitude_rounded  \\\n",
              "0       2020-07-01 00:00:00+00:00   2607    0.0             52.44   \n",
              "1       2020-07-01 00:00:00+00:00   2626    0.0             54.99   \n",
              "2       2020-07-01 00:00:00+00:00   2631    0.0             51.81   \n",
              "3       2020-07-01 00:00:00+00:00   2657    0.0             51.49   \n",
              "4       2020-07-01 00:00:00+00:00   2729    0.0             51.61   \n",
              "...                           ...    ...    ...               ...   \n",
              "6039341 2020-07-31 23:55:00+00:00  18873    0.0             53.59   \n",
              "6039342 2020-07-31 23:55:00+00:00  18989    0.0             53.55   \n",
              "6039343 2020-07-31 23:55:00+00:00  18990    0.0             53.76   \n",
              "6039344 2020-07-31 23:55:00+00:00  22335    0.0             53.10   \n",
              "6039345 2020-07-31 23:55:00+00:00  23083    0.0             53.06   \n",
              "\n",
              "         longitude_rounded  orientation  tilt  altitude  \n",
              "0                    -0.12        200.0  35.0         0  \n",
              "1                    -3.18        270.0  22.0         0  \n",
              "2                    -2.50        130.0  30.0         0  \n",
              "3                     0.36        185.0  47.0         0  \n",
              "4                    -0.24        180.0  45.0         0  \n",
              "...                    ...          ...   ...       ...  \n",
              "6039341              -3.04        290.0  35.0         0  \n",
              "6039342              -2.23        207.0  35.0         0  \n",
              "6039343              -1.52        180.0  34.0         0  \n",
              "6039344              -2.04        140.0  21.0         0  \n",
              "6039345              -2.98        120.0  31.0         0  \n",
              "\n",
              "[6039346 rows x 8 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Merges \n",
        "pv_shared_merge = pv_shared[[\"ss_id\", \"latitude_rounded\", \"longitude_rounded\", \"orientation\", \"tilt\"]]\n",
        "pv_reset = pv.reset_index()\n",
        "\n",
        "pv_az = pd.merge(pv_reset, pv_shared_merge[['ss_id', 'latitude_rounded', 'longitude_rounded', \"orientation\", \"tilt\"]], on='ss_id', how='left').dropna().set_index([\"timestamp\", \"ss_id\"])\n",
        "pv_az[\"altitude\"] = 0\n",
        "pv_az_pre = pv_az.reset_index()\n",
        "pv_az_pre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Calculates the azimuth\n",
        "tz = 'Europe/London'\n",
        "location_data = {\n",
        "    'latitude': pv_az_pre['latitude_rounded'].mean(),  # Using mean latitude and longitude\n",
        "    'longitude': pv_az_pre['longitude_rounded'].mean(),\n",
        "    'altitude': pv_az_pre['altitude'].mean()  # You may want to adjust how you handle altitude\n",
        "}\n",
        "\n",
        "# Convert timestamps from UTC to the UK timezone and sort\n",
        "pv_az_pre['timestamp'] = pd.to_datetime(pv_az_pre['timestamp'], utc=True).dt.tz_convert(tz)\n",
        "\n",
        "# Create a single location object\n",
        "location = pvlib.location.Location(location_data['latitude'], location_data['longitude'], tz, location_data['altitude'])\n",
        "\n",
        "# Calculate solar position for all times at once\n",
        "solar_position = location.get_solarposition(pv_az_pre['timestamp'])\n",
        "\n",
        "# Assign the azimuth values directly\n",
        "pv_az_pre['solar_azimuth'] = solar_position['azimuth'].values\n",
        "pv_az_pre['solar_azimuth_south'] = (pv_az_pre['solar_azimuth'] - 180) % 360\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Calculates the solar zenith and then converts required values to radians\n",
        "tz = 'Europe/London'\n",
        "location_data = {\n",
        "    'latitude': pv_az_pre['latitude_rounded'].mean(),\n",
        "    'longitude': pv_az_pre['longitude_rounded'].mean(),\n",
        "    'altitude': pv_az_pre['altitude'].mean()\n",
        "}\n",
        "\n",
        "# Convert timestamps from UTC to the UK timezone and sort\n",
        "pv_az_pre['timestamp'] = pd.to_datetime(pv_az_pre['timestamp'], utc=True).dt.tz_convert(tz)\n",
        "\n",
        "# Create a single location object\n",
        "location = pvlib.location.Location(\n",
        "    location_data['latitude'], \n",
        "    location_data['longitude'], \n",
        "    tz, \n",
        "    location_data['altitude']\n",
        ")\n",
        "solar_position = location.get_solarposition(pv_az_pre['timestamp'])\n",
        "pv_az_pre['solar_zenith'] = 90 - solar_position['elevation'].values\n",
        "\n",
        "\n",
        "pv_az_pre['solar_azimuth_radians'] = np.radians(pv_az_pre['solar_azimuth'])\n",
        "pv_az_pre['solar_azimuth_south_radians'] = np.radians(pv_az_pre['solar_azimuth_south'])\n",
        "\n",
        "pv_az_pre['solar_zenith_radians'] = np.radians(pv_az_pre['solar_zenith'])\n",
        "pv_az_pre[\"tilt_radians\"] = np.radians(pv_az_pre['tilt'])\n",
        "pv_az_pre[\"latitude_rounded_radians\"] = np.radians(pv_az_pre['latitude_rounded'])\n",
        "pv_az_pre[\"longitude_rounded_radians\"] = np.radians(pv_az_pre['longitude_rounded'])\n",
        "pv_az_pre[\"orientation_radians\"] = np.radians(pv_az_pre['orientation'])\n",
        "\n",
        "pv_az_pre['timestamp'] = pv_az_pre['timestamp'].dt.tz_convert('UTC')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "cos_theta_inc = (\n",
        "    np.sin(pv_az_pre['latitude_rounded_radians']) * np.cos(pv_az_pre['solar_zenith_radians']) * np.cos(pv_az_pre['tilt_radians']) +\n",
        "    np.sin(pv_az_pre['solar_zenith_radians']) * np.cos(pv_az_pre['latitude_rounded_radians']) * np.sin(pv_az_pre['tilt_radians']) * np.cos(pv_az_pre['orientation_radians'] - pv_az_pre['solar_azimuth_south_radians']) +\n",
        "    np.cos(pv_az_pre['solar_zenith_radians']) * np.sin(pv_az_pre['tilt_radians']) * np.sin(pv_az_pre['orientation_radians'] - pv_az_pre['solar_azimuth_south_radians'])\n",
        ")\n",
        "cos_theta_inc = np.clip(cos_theta_inc, -1.0, 1.0)\n",
        "\n",
        "pv_az_pre['angle_of_incidence_radians'] = np.arccos(cos_theta_inc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "pv_inc = pv_az_pre.drop(columns={'latitude_rounded', 'longitude_rounded',\n",
        "       'orientation', 'tilt', 'altitude', 'solar_azimuth',\n",
        "       'solar_azimuth_radians', 'solar_zenith', 'solar_zenith_radians',\n",
        "       'tilt_radians', 'latitude_rounded_radians', 'longitude_rounded_radians',\n",
        "       'orientation_radians', \"solar_azimuth_south\", \"solar_azimuth_south_radians\"}).sort_values([ \"timestamp\"]).set_index([\"timestamp\", \"ss_id\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "pv_inc_chk = pv_inc.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pv_inc.reset_index()\n",
        "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
        "pv_inc = df.set_index([\"timestamp\", \"ss_id\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#check the utc is not causing a mis calculation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Convert to raidians after and the calculate the solar irraidiance "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "inc_id = list(pv_inc.index.get_level_values(1).unique())\n",
        "pv_id = list(pv.index.get_level_values(1).unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Need source on assuming the altitude of the farms "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Not used in this model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Here in these are used for running the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Used for creating the dataloader that passes the data to the model, this needs to be changed if we want to pass in non-hrv data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "jZh7yQM2XoLW"
      },
      "outputs": [],
      "source": [
        "#This function extracts the area around each individual site using the PV dicts pixel based (as in the location of sites are determined by their pixel in the image) location and then extracts an area around each site. These areas are combined, based on their timestamp,\n",
        "#with the HRV data that then has its satellite imagery data extracted. This implies that the model is using subsets of the satellite imagery to train the model to make predictions for each site rather than using the whole image and then \"learning\" where the sites are.\n",
        "\n",
        "class ChallengeDataset(IterableDataset):#This function sets up the data so that it can be iterated through by the CNN\n",
        "    def __init__(self, pv, hrv, site_locations, sites=None):#The \"self\" augmentation here is used to use create a shared class between the different data types that are then iterable based on their shared timestamp\n",
        "        self.pv = pv\n",
        "        self.hrv = hrv\n",
        "        self._site_locations = site_locations\n",
        "        self._sites = sites if sites else list(site_locations[\"hrv\"].keys())#This gets the individual site ids which are stored as the dict's keys\n",
        "\n",
        "    def _get_image_times(self):#This function starts at the minimum date in the set and iterates up to the highest date, this is done as the data set is large and due to the nature of the parquette and xarray\n",
        "        min_date = datetime(2020, 7, 1)\n",
        "        max_date = datetime(2020, 7, 2)\n",
        "        #max and min need to be changed if we use more than one month of data\n",
        "        start_time = time(8)\n",
        "        end_time = time(17)\n",
        "\n",
        "        date = min_date#starts at the first timestamp\n",
        "        while date <= max_date: #iterates through up to the max\n",
        "            current_time = datetime.combine(date, start_time)\n",
        "            while current_time.time() < end_time:\n",
        "                if current_time:\n",
        "                    yield current_time\n",
        "\n",
        "                current_time += timedelta(minutes=60)\n",
        "\n",
        "            date += timedelta(days=1)\n",
        "\n",
        "    def __iter__(self):\n",
        "        for time in self._get_image_times():\n",
        "            first_hour = slice(str(time), str(time + timedelta(minutes=55)))#gets the time and then uses this to select the corresponding time from the pv set  \n",
        "\n",
        "            pv_features = pv.xs(first_hour, drop_level=False)  # this gets the pv yield of the current timestamp selected earlier\n",
        "            pv_targets = pv.xs(\n",
        "                slice(  # type: ignore\n",
        "                    str(time + timedelta(hours=1)),\n",
        "                    str(time + timedelta(hours=4, minutes=55)),\n",
        "                ),\n",
        "                drop_level=False,\n",
        "            )#pv targets defines the time span over which we are trying to make pv yield predictions\n",
        "            #print( pv_features)\n",
        "            #print(pv_features)\n",
        "\n",
        "            hrv_data = self.hrv[\"data\"].sel(time=first_hour).to_numpy()#gets the hrv satellite image that is associated with the first hour timestamp setting it up as an input feature\n",
        "\n",
        "            for site in self._sites:\n",
        "                try:\n",
        "                    # Get solar PV features and targets, the site_targets is used to find the models loss\n",
        "                    site_features = pv_features.xs(site, level=1).to_numpy().squeeze(-1)#gets the pixel based location of the pv site and then uses this to make predictions based on the individual sites\n",
        "                    site_targets = pv_targets.xs(site, level=1).to_numpy().squeeze(-1)\n",
        "                    assert site_features.shape == (12,) and site_targets.shape == (48,)#compresses the data from N dimensions to 12 and 48 respectively\n",
        "                    print(site)\n",
        "                    #print(site)\n",
        "                    # Get a 128x128 HRV crop centred on the site over the previous hour\n",
        "                    x, y = self._site_locations[\"hrv\"][site]#gets the location of the site based on the pv sites pixel level location\n",
        "                    hrv_features = hrv_data[:, y - 64 : y + 64, x - 64 : x + 64, 0]\n",
        "                    assert hrv_features.shape == (12, 128, 128)#crops the image to be be 128x128 around the site\n",
        "                    #asset is used to force the dimensions of the extracted site level image to be the same\n",
        "                    # How might you adapt this for the non-HRV, weather and aerosol data?\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "                yield site_features, hrv_features, site_targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2607\n",
            "PV Features for the first site:\n",
            "[0.24236082 0.25453959 0.18922122 0.16577837 0.20899755 0.22073959\n",
            " 0.24724816 0.22385347 0.21168286 0.32554163 0.30427714 0.21674857]\n"
          ]
        }
      ],
      "source": [
        "dataset = ChallengeDataset( pv, hrv, site_locations)\n",
        "\n",
        "# Iterate over the dataset and break after the first iteration to print the pv_features\n",
        "for pv_features, hrv_features, site_targets in dataset:\n",
        "    # Assuming you want to print the pv_features for the first site\n",
        "    print(\"PV Features for the first site:\")\n",
        "    print(pv_features)\n",
        "    break "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {},
      "outputs": [],
      "source": [
        "#This function extracts the area around each individual site using the PV dicts pixel based (as in the location of sites are determined by their pixel in the image) location and then extracts an area around each site. These areas are combined, based on their timestamp,\n",
        "#with the HRV data that then has its satellite imagery data extracted. This implies that the model is using subsets of the satellite imagery to train the model to make predictions for each site rather than using the whole image and then \"learning\" where the sites are.\n",
        "\n",
        "class ChallengeDataset_inc(IterableDataset):#This function sets up the data so that it can be iterated through by the CNN\n",
        "    def __init__(self,  pv_inc, hrv, site_locations, sites=None):#The \"self\" augmentation here is used to use create a shared class between the different data types that are then iterable based on their shared timestamp\n",
        "        #self.pv = pv\n",
        "        self.pv_inc = pv_inc\n",
        "        self.hrv = hrv\n",
        "        self._site_locations = site_locations\n",
        "        self._sites = sites if sites else list(site_locations[\"hrv\"].keys())#This gets the individual site ids which are stored as the dict's keys\n",
        "\n",
        "    def _get_image_times(self):#This function starts at the minimum date in the set and iterates up to the highest date, this is done as the data set is large and due to the nature of the parquette and xarray\n",
        "        min_date = datetime(2020, 7, 1)\n",
        "        max_date = datetime(2020, 7, 2)\n",
        "        #max and min need to be changed if we use more than one month of data\n",
        "        start_time = time(8)\n",
        "        end_time = time(17)\n",
        "\n",
        "        date = min_date#starts at the first timestamp\n",
        "        while date <= max_date: #iterates through up to the max\n",
        "            current_time = datetime.combine(date, start_time)\n",
        "            while current_time.time() < end_time:\n",
        "                if current_time:\n",
        "                    yield current_time\n",
        "\n",
        "                current_time += timedelta(minutes=60)\n",
        "\n",
        "            date += timedelta(days=1)\n",
        "\n",
        "    def __iter__(self):\n",
        "        for time in self._get_image_times():\n",
        "            first_hour = slice(str(time), str(time + timedelta(minutes=55)))#gets the time and then uses this to select the corresponding time from the pv set  \n",
        "            #print(\"Available columns in pv_inc:\", self.pv_inc.columns)\n",
        "           \n",
        "            pv_features = self.pv_inc.xs(first_hour, drop_level=False)[[\"power\", \"angle_of_incidence_radians\"]]\n",
        "\n",
        "        # Fetching PV targets for the future time span\n",
        "            pv_targets = self.pv_inc.xs(\n",
        "                slice(\n",
        "                    str(time + timedelta(hours=1)),  # Start 1 hour after the first_hour\n",
        "                    str(time + timedelta(hours=4, minutes=55)),  # Up to almost 5 hours later\n",
        "                ),\n",
        "                drop_level=False,\n",
        "            )[\"power\"]\n",
        "            #print(\"First hour slice:\", first_hour)\n",
        "            #print(\"Sample data from pv_inc:\", self.pv_inc.xs(first_hour, drop_level=False).head())\n",
        "            #gets the hrv satellite image that is associated with the first hour timestamp setting it up as an input feature\n",
        "            hrv_data = self.hrv['data'].sel(time=first_hour).to_numpy()\n",
        "\n",
        "            for site in self._sites:\n",
        "                try:\n",
        "                    #print(site)\n",
        "                    # Get solar PV features and targets, the site_targets is used to find the models loss\n",
        "                    site_features = pv_features.xs(site, level=1).to_numpy()#.squeeze(-1)#gets the pixel based location of the pv site and then uses this to make predictions based on the individual sites\n",
        "                    \n",
        "                    site_targets = pv_targets.xs(site, level=1).to_numpy()#.squeeze(-1)\n",
        "                    assert site_features.shape == (12,2) and site_targets.shape == (48,)#compresses the data from N dimensions to 12 and 48 respectively\n",
        "                  \n",
        "                    # Get a 128x128 HRV crop centred on the site over the previous hour\n",
        "                    x, y = self._site_locations[\"hrv\"][site]#gets the location of the site based on the pv sites pixel level location\n",
        "                    hrv_features = hrv_data[:, y - 64 : y + 64, x - 64 : x + 64, 0]\n",
        "                    assert hrv_features.shape == (12, 128, 128)#crops the image to be be 128x128 around the site\n",
        "                    #asset is used to force the dimensions of the extracted site level image to be the same\n",
        "                    # How might you adapt this for the non-HRV, weather and aerosol data?\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "                yield site_features, hrv_features, site_targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PV Features for the first site:\n",
            "(12, 2)\n"
          ]
        }
      ],
      "source": [
        "dataset = ChallengeDataset_inc( pv_inc, hrv, site_locations)\n",
        "\n",
        "# Iterate over the dataset and break after the first iteration to print the pv_features\n",
        "for pv_features, hrv_features, site_features in dataset:\n",
        "    # Assuming you want to print the pv_features for the first site\n",
        "    print(\"PV Features for the first site:\")\n",
        "    print(pv_features.shape)\n",
        "    break "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [],
      "source": [
        "layers = [4, 4, 4, 4] #Change this to change the number of layers that you are using, \n",
        "\n",
        "def conv_block(in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
        "    #This section creates a sequence of layers that perform the networks convolution which are applied iteratively in the Resnet_light block\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding), #Feature extraction\n",
        "        nn.BatchNorm2d(out_channels), #Noramlises the outputs from the convolution layers\n",
        "        nn.ReLU(inplace=True)#Applies the activation function\n",
        "    )\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1 \n",
        "    #Applies the convolution established in the previous layer twice giving the F(x) portion of the resnet model\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv_block(in_channels, out_channels, stride=stride)\n",
        "        self.conv2 = conv_block(out_channels, out_channels)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x): #Keeps the x portion of the resnet \n",
        "        identity = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        if self.downsample is not None: #Downsamples the model if needed to match the dimensions of outputs if the identity output does not match the F(x) portion of the output\n",
        "            identity = self.downsample(x)\n",
        "        out = out + identity #Creates the F(x) + x that is then passed to the relu activation function between the resnet conv layers\n",
        "        return F.relu(out, inplace=False)  #Relu applied to combined results, \n",
        "\n",
        "class ResNet_light_inc(nn.Module):\n",
        "    #This class stacks the multiple basic blocks set up in the previous functions\n",
        "    def __init__(self, block, layers):\n",
        "        #I Think we can reduce the number of layers here as the model is applied four convolutions to generate F(x), the resnet paper uses two.\n",
        "        super(ResNet_light_inc, self).__init__()\n",
        "        self.in_channels = 12 #reduce the stride\n",
        "        self.initial = conv_block(12, 12, kernel_size=2, stride=1, padding=3)#Applies the initial convolution \n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2, padding=1)#Runs maxpool convolution\n",
        "        self.layer1 = self._make_layer(block, 12, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 24, layers[1], stride=1)\n",
        "        self.layer3 = self._make_layer(block, 48, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 96, layers[3], stride=1)\n",
        "        self.avgpool = nn.AdaptiveMaxPool2d((1, 1))#Forces the consistency of output sizes to be 1x1 \n",
        "        # Adjust this linear layer based on the concatenated size of HRV and PV features\n",
        "        self.fc = nn.Linear(96  + 12, 48)  #takes the flatterened output of the conv layers for the 12 hourly time instances and then hands them to 48 different class outputs\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride=1):#Used to stack the multiple layers of the resnet model\n",
        "        downsample = None#This checks to make sure that the stride applied matches between input tensor and the output tensor, I am not completely sure if this changes the dimensions of the output tensor\n",
        "        if stride != 1 or self.in_channels != out_channels * block.expansion:#Expands the number of outputs compared to the inputs, for the BasicBlock typically no expansion is needed. This is still needed for the model to run. \n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * block.expansion),\n",
        "            )\n",
        "        layers = [block(self.in_channels, out_channels, stride, downsample)]#This section creates a series of blocks for the layer\n",
        "        self.in_channels = out_channels * block.expansion #Ensures that after the blocks have been defined the next layer gets the correct number of input channels\n",
        "        for _ in range(1, num_blocks):\n",
        "            layers.append(block(self.in_channels, out_channels))#\n",
        "        return nn.Sequential(*layers)#Stretches the dims of the resnet to match the layers defined above\n",
        "        #Need to clarify exactly what expansion is doing.\n",
        "    def forward(self, pv_inc, hrv ):#Defines how the model passes the outputs through the network\n",
        "        #print(\"Initial HRV shape:\", hrv.shape)  \n",
        "        #print(\"Initial PV shape:\", pv.shape) \n",
        "        #print(f\"{pv[0]}\")\n",
        "        x = self.initial(hrv)#Passes the HRV data through the initial block defined earlier\n",
        "        x = self.maxpool(x)#Downsamples using maxpooling\n",
        "        #print(\"Shape after initial conv and maxpool:\", x.shape)\n",
        "\n",
        "        x = self.layer1(x)#Applies the layers defined above, \n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        #print(\"Shape after ResNet_light blocks:\", x.shape)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        #print(\"Shape after avgpool:\", x.shape)\n",
        "        x = torch.flatten(x, 1)# Applies the flattering to the second dimension as the first dimension is the batch size\n",
        "        pv_inc = torch.flatten(pv_inc, start_dim=1)#Flattens the pv data so that the dimensions of the pv tensor match the dimensions of the HRV tensor\n",
        "        #print(f\"Sshape of x = {x.shape} shape of pv = {pv.shape}\")\n",
        "        #x = torch.concat((x, pv), dim=-1)\n",
        "        #print(\"Shape after avgpool and flatten:\", x.shape)\n",
        "\n",
        "        \n",
        "        \n",
        "        #pv = pv.view(pv.size(0), -1)\n",
        "        #Checks to make sure that the pv tensor dimensions match the HRV tensor dimensions\n",
        "        if pv.dim() > 2:\n",
        "            pv = torch.flatten(pv_inc, start_dim=1)\n",
        "        #print(\"Adjusted PV shape:\", pv.shape)\n",
        "\n",
        "        combined = torch.cat((x, pv_inc), dim=1)#Combines the pv and hrv data along the feature dimension\n",
        "\n",
        "        if self.fc.in_features != combined.shape[1]:\n",
        "            self.fc = nn.Linear(combined.shape[1], 48).to(combined.device)\n",
        "            #Above runs a check to make sure that the number of input features is correct\n",
        "        out = self.fc(combined) #takes the combined output of the pv and hrv and passes them to the fully connected layer defined above\n",
        "        return out\n",
        "model_light_res_inc = ResNet_light_inc(BasicBlock, layers).to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Solar angle model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [],
      "source": [
        "def conv_block(in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv_block(in_channels, out_channels, stride=stride)\n",
        "        self.conv2 = conv_block(out_channels, out_channels)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "        out = out + identity\n",
        "        return F.relu(out, inplace=False)\n",
        "\n",
        "class ResNet_light_inc(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers):\n",
        "        super(ResNet_light_inc, self).__init__()\n",
        "        self.in_channels = 12\n",
        "        self.initial = conv_block(12, 12, kernel_size=2, stride=1, padding=3)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 12, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 24, layers[1], stride=1)\n",
        "        self.layer3 = self._make_layer(block, 48, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 96, layers[3], stride=1)\n",
        "        self.avgpool = nn.AdaptiveMaxPool2d((1, 1))\n",
        "        self.fc = nn.Linear(96 + 24, 48)#Might need to adjust the 24 for the amount of features trained on\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * block.expansion),\n",
        "            )\n",
        "        layers = [block(self.in_channels, out_channels, stride, downsample)]\n",
        "        self.in_channels = out_channels * block.expansion\n",
        "        for _ in range(1, num_blocks):\n",
        "            layers.append(block(self.in_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, pv_inc, hrv):\n",
        "        x = self.initial(hrv)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        pv_inc = torch.flatten(pv_inc, start_dim=1)\n",
        "        if pv_inc.dim() > 2:\n",
        "            pv_inc = torch.flatten(pv_inc, start_dim=1)\n",
        "        combined = torch.cat((x, pv_inc), dim=1)\n",
        "        #This line might increase computational intensity\n",
        "        if self.fc.in_features != combined.shape[1]:\n",
        "            self.fc = nn.Linear(combined.shape[1], 48).to(combined.device)\n",
        "        out = self.fc(combined)\n",
        "        return out\n",
        "\n",
        "model_light_res_inc = ResNet_light_inc(BasicBlock, layers).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install torchsummary\n",
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "ResNet_light_inc                         [1, 48]                   5,808\n",
              "├─Sequential: 1-1                        [1, 12, 133, 133]         --\n",
              "│    └─Conv2d: 2-1                       [1, 12, 133, 133]         588\n",
              "│    └─BatchNorm2d: 2-2                  [1, 12, 133, 133]         24\n",
              "│    └─ReLU: 2-3                         [1, 12, 133, 133]         --\n",
              "├─MaxPool2d: 1-2                         [1, 12, 67, 67]           --\n",
              "├─Sequential: 1-3                        [1, 12, 67, 67]           --\n",
              "│    └─BasicBlock: 2-4                   [1, 12, 67, 67]           --\n",
              "│    │    └─Sequential: 3-1              [1, 12, 67, 67]           1,332\n",
              "│    │    └─Sequential: 3-2              [1, 12, 67, 67]           1,332\n",
              "│    └─BasicBlock: 2-5                   [1, 12, 67, 67]           --\n",
              "│    │    └─Sequential: 3-3              [1, 12, 67, 67]           1,332\n",
              "│    │    └─Sequential: 3-4              [1, 12, 67, 67]           1,332\n",
              "│    └─BasicBlock: 2-6                   [1, 12, 67, 67]           --\n",
              "│    │    └─Sequential: 3-5              [1, 12, 67, 67]           1,332\n",
              "│    │    └─Sequential: 3-6              [1, 12, 67, 67]           1,332\n",
              "│    └─BasicBlock: 2-7                   [1, 12, 67, 67]           --\n",
              "│    │    └─Sequential: 3-7              [1, 12, 67, 67]           1,332\n",
              "│    │    └─Sequential: 3-8              [1, 12, 67, 67]           1,332\n",
              "├─Sequential: 1-4                        [1, 24, 67, 67]           --\n",
              "│    └─BasicBlock: 2-8                   [1, 24, 67, 67]           --\n",
              "│    │    └─Sequential: 3-9              [1, 24, 67, 67]           2,664\n",
              "│    │    └─Sequential: 3-10             [1, 24, 67, 67]           5,256\n",
              "│    │    └─Sequential: 3-11             [1, 24, 67, 67]           336\n",
              "│    └─BasicBlock: 2-9                   [1, 24, 67, 67]           --\n",
              "│    │    └─Sequential: 3-12             [1, 24, 67, 67]           5,256\n",
              "│    │    └─Sequential: 3-13             [1, 24, 67, 67]           5,256\n",
              "│    └─BasicBlock: 2-10                  [1, 24, 67, 67]           --\n",
              "│    │    └─Sequential: 3-14             [1, 24, 67, 67]           5,256\n",
              "│    │    └─Sequential: 3-15             [1, 24, 67, 67]           5,256\n",
              "│    └─BasicBlock: 2-11                  [1, 24, 67, 67]           --\n",
              "│    │    └─Sequential: 3-16             [1, 24, 67, 67]           5,256\n",
              "│    │    └─Sequential: 3-17             [1, 24, 67, 67]           5,256\n",
              "├─Sequential: 1-5                        [1, 48, 34, 34]           --\n",
              "│    └─BasicBlock: 2-12                  [1, 48, 34, 34]           --\n",
              "│    │    └─Sequential: 3-18             [1, 48, 34, 34]           10,512\n",
              "│    │    └─Sequential: 3-19             [1, 48, 34, 34]           20,880\n",
              "│    │    └─Sequential: 3-20             [1, 48, 34, 34]           1,248\n",
              "│    └─BasicBlock: 2-13                  [1, 48, 34, 34]           --\n",
              "│    │    └─Sequential: 3-21             [1, 48, 34, 34]           20,880\n",
              "│    │    └─Sequential: 3-22             [1, 48, 34, 34]           20,880\n",
              "│    └─BasicBlock: 2-14                  [1, 48, 34, 34]           --\n",
              "│    │    └─Sequential: 3-23             [1, 48, 34, 34]           20,880\n",
              "│    │    └─Sequential: 3-24             [1, 48, 34, 34]           20,880\n",
              "│    └─BasicBlock: 2-15                  [1, 48, 34, 34]           --\n",
              "│    │    └─Sequential: 3-25             [1, 48, 34, 34]           20,880\n",
              "│    │    └─Sequential: 3-26             [1, 48, 34, 34]           20,880\n",
              "├─Sequential: 1-6                        [1, 96, 34, 34]           --\n",
              "│    └─BasicBlock: 2-16                  [1, 96, 34, 34]           --\n",
              "│    │    └─Sequential: 3-27             [1, 96, 34, 34]           41,760\n",
              "│    │    └─Sequential: 3-28             [1, 96, 34, 34]           83,232\n",
              "│    │    └─Sequential: 3-29             [1, 96, 34, 34]           4,800\n",
              "│    └─BasicBlock: 2-17                  [1, 96, 34, 34]           --\n",
              "│    │    └─Sequential: 3-30             [1, 96, 34, 34]           83,232\n",
              "│    │    └─Sequential: 3-31             [1, 96, 34, 34]           83,232\n",
              "│    └─BasicBlock: 2-18                  [1, 96, 34, 34]           --\n",
              "│    │    └─Sequential: 3-32             [1, 96, 34, 34]           83,232\n",
              "│    │    └─Sequential: 3-33             [1, 96, 34, 34]           83,232\n",
              "│    └─BasicBlock: 2-19                  [1, 96, 34, 34]           --\n",
              "│    │    └─Sequential: 3-34             [1, 96, 34, 34]           83,232\n",
              "│    │    └─Sequential: 3-35             [1, 96, 34, 34]           83,232\n",
              "├─AdaptiveMaxPool2d: 1-7                 [1, 96, 1, 1]             --\n",
              "==========================================================================================\n",
              "Total params: 843,972\n",
              "Trainable params: 843,972\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 1.14\n",
              "==========================================================================================\n",
              "Input size (MB): 0.79\n",
              "Forward/backward pass size (MB): 49.78\n",
              "Params size (MB): 3.35\n",
              "Estimated Total Size (MB): 53.92\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 138,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hrv_input_size = (1, 12, 224, 224)  # For example: batch size of 1, 12 channels, 224x224 height and width\n",
        "pv_input_size = (1, 1, 224, 224)    # For example: batch size of 1, 1 channel, 224x224 height and width\n",
        "\n",
        "# You need to provide the sizes in a list if your model expects multiple inputs\n",
        "model_input_sizes = [hrv_input_size, pv_input_size]\n",
        "\n",
        "# Use torchinfo's summary function\n",
        "# The input size is passed as a list of tuples, each corresponding to the size of an input the model expects\n",
        "summary(model_light_res_inc, input_size=[(1, 12), (1, 12, 128, 128)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lighter weight resnet, I have commented out this model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "layers = [2, 2, 2, 2] #Change this to change the number of layers that you are using, \n",
        "\n",
        "def conv_block(in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
        "    #This section creates a sequence of layers that perform the networks convolution which are applied iteratively in the Resnet_light block\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding), #Feature extraction\n",
        "        nn.BatchNorm2d(out_channels), #Noramlises the outputs from the convolution layers\n",
        "        nn.ReLU(inplace=True)#Applies the activation function\n",
        "    )\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1 \n",
        "    #Applies the convolution established in the previous layer twice giving the F(x) portion of the resnet model\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv_block(in_channels, out_channels, stride=stride)\n",
        "        self.conv2 = conv_block(out_channels, out_channels)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x): #Keeps the x portion of the resnet \n",
        "        identity = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        if self.downsample is not None: #Downsamples the model if needed to match the dimensions of outputs if the identity output does not match the F(x) portion of the output\n",
        "            identity = self.downsample(x)\n",
        "        out = out + identity #Creates the F(x) + x that is then passed to the relu activation function between the resnet conv layers\n",
        "        return F.relu(out, inplace=False)  #Relu applied to combined results, \n",
        "\n",
        "class ResNet_light(nn.Module):\n",
        "    #This class stacks the multiple basic blocks set up in the previous functions\n",
        "    def __init__(self, block, layers):\n",
        "        #I Think we can reduce the number of layers here as the model is applied four convolutions to generate F(x), the resnet paper uses two.\n",
        "        super(ResNet_light, self).__init__()\n",
        "        self.in_channels = 12 #reduce the stride\n",
        "        self.initial = conv_block(12, 12, kernel_size=2, stride=1, padding=3)#Applies the initial convolution \n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2, padding=1)#Runs maxpool convolution\n",
        "        self.layer1 = self._make_layer(block, 12, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 24, layers[1], stride=1)\n",
        "        self.layer3 = self._make_layer(block, 48, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 96, layers[3], stride=1)\n",
        "        self.avgpool = nn.AdaptiveMaxPool2d((1, 1))#Forces the consistency of output sizes to be 1x1 \n",
        "        # Adjust this linear layer based on the concatenated size of HRV and PV features\n",
        "        self.fc = nn.Linear(96  + 12, 48)  #takes the flatterened output of the conv layers for the 12 hourly time instances and then hands them to 48 different class outputs\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride=1):#Used to stack the multiple layers of the resnet model\n",
        "        downsample = None#This checks to make sure that the stride applied matches between input tensor and the output tensor, I am not completely sure if this changes the dimensions of the output tensor\n",
        "        if stride != 1 or self.in_channels != out_channels * block.expansion:#Expands the number of outputs compared to the inputs, for the BasicBlock typically no expansion is needed. This is still needed for the model to run. \n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * block.expansion),\n",
        "            )\n",
        "        layers = [block(self.in_channels, out_channels, stride, downsample)]#This section creates a series of blocks for the layer\n",
        "        self.in_channels = out_channels * block.expansion #Ensures that after the blocks have been defined the next layer gets the correct number of input channels\n",
        "        for _ in range(1, num_blocks):\n",
        "            layers.append(block(self.in_channels, out_channels))#\n",
        "        return nn.Sequential(*layers)#Stretches the dims of the resnet to match the layers defined above\n",
        "        #Need to clarify exactly what expansion is doing.\n",
        "    def forward(self, pv, hrv ):#Defines how the model passes the outputs through the network\n",
        "        #print(\"Initial HRV shape:\", hrv.shape)  \n",
        "        #print(\"Initial PV shape:\", pv.shape) \n",
        "        #print(f\"{pv[0]}\")\n",
        "        x = self.initial(hrv)#Passes the HRV data through the initial block defined earlier\n",
        "        x = self.maxpool(x)#Downsamples using maxpooling\n",
        "        #print(\"Shape after initial conv and maxpool:\", x.shape)\n",
        "\n",
        "        x = self.layer1(x)#Applies the layers defined above, \n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        #print(\"Shape after ResNet_light blocks:\", x.shape)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        #print(\"Shape after avgpool:\", x.shape)\n",
        "        x = torch.flatten(x, 1)# Applies the flattering to the second dimension as the first dimension is the batch size\n",
        "        pv = torch.flatten(pv, start_dim=1)#Flattens the pv data so that the dimensions of the pv tensor match the dimensions of the HRV tensor\n",
        "        #print(f\"Sshape of x = {x.shape} shape of pv = {pv.shape}\")\n",
        "        #x = torch.concat((x, pv), dim=-1)\n",
        "        #print(\"Shape after avgpool and flatten:\", x.shape)\n",
        "\n",
        "        \n",
        "        \n",
        "        #pv = pv.view(pv.size(0), -1)\n",
        "        #Checks to make sure that the pv tensor dimensions match the HRV tensor dimensions\n",
        "        if pv.dim() > 2:\n",
        "            pv = torch.flatten(pv, start_dim=1)\n",
        "        #print(\"Adjusted PV shape:\", pv.shape)\n",
        "\n",
        "        combined = torch.cat((x, pv), dim=1)#Combines the pv and hrv data along the feature dimension\n",
        "\n",
        "        if self.fc.in_features != combined.shape[1]:\n",
        "            self.fc = nn.Linear(combined.shape[1], 48).to(combined.device)\n",
        "            #Above runs a check to make sure that the number of input features is correct\n",
        "        out = self.fc(combined) #takes the combined output of the pv and hrv and passes them to the fully connected layer defined above\n",
        "        return out\n",
        "model_light_res = ResNet_light(BasicBlock, layers).to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Deeper light weight resnet, good performance over a day and trains quickly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "layers = [4, 4, 4, 4] #For a deeper resnet with 16 total conv layers\n",
        "\n",
        "def conv_block(in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv_block(in_channels, out_channels, stride=stride)\n",
        "        self.conv2 = conv_block(out_channels, out_channels)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "        out = out + identity\n",
        "        return F.relu(out, inplace=False)\n",
        "\n",
        "class ResNet_light_deep(nn.Module):\n",
        "    \n",
        "    def __init__(self, block, layers):\n",
        "        \n",
        "        super(ResNet_light_deep, self).__init__()\n",
        "        self.in_channels = 12 #reduce the stride\n",
        "        self.initial = conv_block(12, 12, kernel_size=2, stride=1, padding=3)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 12, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 24, layers[1], stride=1)\n",
        "        self.layer3 = self._make_layer(block, 48, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 96, layers[3], stride=1)\n",
        "        self.avgpool = nn.AdaptiveMaxPool2d((1, 1))\n",
        "        # Adjust this linear layer based on the concatenated size of HRV and PV features\n",
        "        self.fc = nn.Linear(96  + 12, 48)  \n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * block.expansion),\n",
        "            )\n",
        "        layers = [block(self.in_channels, out_channels, stride, downsample)]\n",
        "        self.in_channels = out_channels * block.expansion\n",
        "        for _ in range(1, num_blocks):\n",
        "            layers.append(block(self.in_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, pv, hrv ):\n",
        "        #print(\"Initial HRV shape:\", hrv.shape)  \n",
        "        #print(\"Initial PV shape:\", pv.shape) \n",
        "        #print(f\"{pv[0]}\")\n",
        "        x = self.initial(hrv)\n",
        "        x = self.maxpool(x)\n",
        "        #print(\"Shape after initial conv and maxpool:\", x.shape)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        #print(\"Shape after ResNet_light blocks:\", x.shape)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        #print(\"Shape after avgpool:\", x.shape)\n",
        "        x = torch.flatten(x, 1)\n",
        "        pv = torch.flatten(pv, start_dim=1)\n",
        "        #print(f\"Sshape of x = {x.shape} shape of pv = {pv.shape}\")\n",
        "        #x = torch.concat((x, pv), dim=-1)\n",
        "        #print(\"Shape after avgpool and flatten:\", x.shape)\n",
        "\n",
        "        \n",
        "        \n",
        "        #pv = pv.view(pv.size(0), -1)\n",
        "        if pv.dim() > 2:\n",
        "            pv = torch.flatten(pv, start_dim=1)\n",
        "        #print(\"Adjusted PV shape:\", pv.shape)\n",
        "\n",
        "        combined = torch.cat((x, pv), dim=1)\n",
        "\n",
        "        if self.fc.in_features != combined.shape[1]:\n",
        "            self.fc = nn.Linear(combined.shape[1], 48).to(combined.device)\n",
        "\n",
        "        out = self.fc(combined)\n",
        "        return out\n",
        "model_light_deep_res = ResNet_light_deep(BasicBlock, layers).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#how do we make sure that thi is sequence to sequence and not a sequence to one "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output for the lighter weight resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "ResNet_light                             [1, 48]                   --\n",
              "├─Sequential: 1-1                        [1, 12, 133, 133]         --\n",
              "│    └─Conv2d: 2-1                       [1, 12, 133, 133]         588\n",
              "│    └─BatchNorm2d: 2-2                  [1, 12, 133, 133]         24\n",
              "│    └─ReLU: 2-3                         [1, 12, 133, 133]         --\n",
              "├─MaxPool2d: 1-2                         [1, 12, 67, 67]           --\n",
              "├─Sequential: 1-3                        [1, 12, 67, 67]           --\n",
              "│    └─BasicBlock: 2-4                   [1, 12, 67, 67]           --\n",
              "│    │    └─Sequential: 3-1              [1, 12, 67, 67]           1,332\n",
              "│    │    └─Sequential: 3-2              [1, 12, 67, 67]           1,332\n",
              "│    └─BasicBlock: 2-5                   [1, 12, 67, 67]           --\n",
              "│    │    └─Sequential: 3-3              [1, 12, 67, 67]           1,332\n",
              "│    │    └─Sequential: 3-4              [1, 12, 67, 67]           1,332\n",
              "├─Sequential: 1-4                        [1, 24, 67, 67]           --\n",
              "│    └─BasicBlock: 2-6                   [1, 24, 67, 67]           --\n",
              "│    │    └─Sequential: 3-5              [1, 24, 67, 67]           2,664\n",
              "│    │    └─Sequential: 3-6              [1, 24, 67, 67]           5,256\n",
              "│    │    └─Sequential: 3-7              [1, 24, 67, 67]           336\n",
              "│    └─BasicBlock: 2-7                   [1, 24, 67, 67]           --\n",
              "│    │    └─Sequential: 3-8              [1, 24, 67, 67]           5,256\n",
              "│    │    └─Sequential: 3-9              [1, 24, 67, 67]           5,256\n",
              "├─Sequential: 1-5                        [1, 48, 34, 34]           --\n",
              "│    └─BasicBlock: 2-8                   [1, 48, 34, 34]           --\n",
              "│    │    └─Sequential: 3-10             [1, 48, 34, 34]           10,512\n",
              "│    │    └─Sequential: 3-11             [1, 48, 34, 34]           20,880\n",
              "│    │    └─Sequential: 3-12             [1, 48, 34, 34]           1,248\n",
              "│    └─BasicBlock: 2-9                   [1, 48, 34, 34]           --\n",
              "│    │    └─Sequential: 3-13             [1, 48, 34, 34]           20,880\n",
              "│    │    └─Sequential: 3-14             [1, 48, 34, 34]           20,880\n",
              "├─Sequential: 1-6                        [1, 96, 34, 34]           --\n",
              "│    └─BasicBlock: 2-10                  [1, 96, 34, 34]           --\n",
              "│    │    └─Sequential: 3-15             [1, 96, 34, 34]           41,760\n",
              "│    │    └─Sequential: 3-16             [1, 96, 34, 34]           83,232\n",
              "│    │    └─Sequential: 3-17             [1, 96, 34, 34]           4,800\n",
              "│    └─BasicBlock: 2-11                  [1, 96, 34, 34]           --\n",
              "│    │    └─Sequential: 3-18             [1, 96, 34, 34]           83,232\n",
              "│    │    └─Sequential: 3-19             [1, 96, 34, 34]           83,232\n",
              "├─AdaptiveMaxPool2d: 1-7                 [1, 96, 1, 1]             --\n",
              "├─Linear: 1-8                            [1, 48]                   5,232\n",
              "==========================================================================================\n",
              "Total params: 400,596\n",
              "Trainable params: 400,596\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 543.88\n",
              "==========================================================================================\n",
              "Input size (MB): 0.79\n",
              "Forward/backward pass size (MB): 28.78\n",
              "Params size (MB): 1.60\n",
              "Estimated Total Size (MB): 31.17\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hrv_input_size = (1, 12, 224, 224)  # For example: batch size of 1, 12 channels, 224x224 height and width\n",
        "pv_input_size = (1, 1, 224, 224)    # For example: batch size of 1, 1 channel, 224x224 height and width\n",
        "\n",
        "# You need to provide the sizes in a list if your model expects multiple inputs\n",
        "model_input_sizes = [hrv_input_size, pv_input_size]\n",
        "\n",
        "# Use torchinfo's summary function\n",
        "# The input size is passed as a list of tuples, each corresponding to the size of an input the model expects\n",
        "summary(model_light_res, input_size=[(1, 12), (1, 12, 128, 128)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output for the light weight deeper resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "ResNet_light_deep                        [1, 48]                   --\n",
              "├─Sequential: 1-1                        [1, 12, 133, 133]         --\n",
              "│    └─Conv2d: 2-1                       [1, 12, 133, 133]         588\n",
              "│    └─BatchNorm2d: 2-2                  [1, 12, 133, 133]         24\n",
              "│    └─ReLU: 2-3                         [1, 12, 133, 133]         --\n",
              "├─MaxPool2d: 1-2                         [1, 12, 67, 67]           --\n",
              "├─Sequential: 1-3                        [1, 12, 67, 67]           --\n",
              "│    └─BasicBlock: 2-4                   [1, 12, 67, 67]           --\n",
              "│    │    └─Sequential: 3-1              [1, 12, 67, 67]           1,332\n",
              "│    │    └─Sequential: 3-2              [1, 12, 67, 67]           1,332\n",
              "│    └─BasicBlock: 2-5                   [1, 12, 67, 67]           --\n",
              "│    │    └─Sequential: 3-3              [1, 12, 67, 67]           1,332\n",
              "│    │    └─Sequential: 3-4              [1, 12, 67, 67]           1,332\n",
              "│    └─BasicBlock: 2-6                   [1, 12, 67, 67]           --\n",
              "│    │    └─Sequential: 3-5              [1, 12, 67, 67]           1,332\n",
              "│    │    └─Sequential: 3-6              [1, 12, 67, 67]           1,332\n",
              "│    └─BasicBlock: 2-7                   [1, 12, 67, 67]           --\n",
              "│    │    └─Sequential: 3-7              [1, 12, 67, 67]           1,332\n",
              "│    │    └─Sequential: 3-8              [1, 12, 67, 67]           1,332\n",
              "├─Sequential: 1-4                        [1, 24, 67, 67]           --\n",
              "│    └─BasicBlock: 2-8                   [1, 24, 67, 67]           --\n",
              "│    │    └─Sequential: 3-9              [1, 24, 67, 67]           2,664\n",
              "│    │    └─Sequential: 3-10             [1, 24, 67, 67]           5,256\n",
              "│    │    └─Sequential: 3-11             [1, 24, 67, 67]           336\n",
              "│    └─BasicBlock: 2-9                   [1, 24, 67, 67]           --\n",
              "│    │    └─Sequential: 3-12             [1, 24, 67, 67]           5,256\n",
              "│    │    └─Sequential: 3-13             [1, 24, 67, 67]           5,256\n",
              "│    └─BasicBlock: 2-10                  [1, 24, 67, 67]           --\n",
              "│    │    └─Sequential: 3-14             [1, 24, 67, 67]           5,256\n",
              "│    │    └─Sequential: 3-15             [1, 24, 67, 67]           5,256\n",
              "│    └─BasicBlock: 2-11                  [1, 24, 67, 67]           --\n",
              "│    │    └─Sequential: 3-16             [1, 24, 67, 67]           5,256\n",
              "│    │    └─Sequential: 3-17             [1, 24, 67, 67]           5,256\n",
              "├─Sequential: 1-5                        [1, 48, 34, 34]           --\n",
              "│    └─BasicBlock: 2-12                  [1, 48, 34, 34]           --\n",
              "│    │    └─Sequential: 3-18             [1, 48, 34, 34]           10,512\n",
              "│    │    └─Sequential: 3-19             [1, 48, 34, 34]           20,880\n",
              "│    │    └─Sequential: 3-20             [1, 48, 34, 34]           1,248\n",
              "│    └─BasicBlock: 2-13                  [1, 48, 34, 34]           --\n",
              "│    │    └─Sequential: 3-21             [1, 48, 34, 34]           20,880\n",
              "│    │    └─Sequential: 3-22             [1, 48, 34, 34]           20,880\n",
              "│    └─BasicBlock: 2-14                  [1, 48, 34, 34]           --\n",
              "│    │    └─Sequential: 3-23             [1, 48, 34, 34]           20,880\n",
              "│    │    └─Sequential: 3-24             [1, 48, 34, 34]           20,880\n",
              "│    └─BasicBlock: 2-15                  [1, 48, 34, 34]           --\n",
              "│    │    └─Sequential: 3-25             [1, 48, 34, 34]           20,880\n",
              "│    │    └─Sequential: 3-26             [1, 48, 34, 34]           20,880\n",
              "├─Sequential: 1-6                        [1, 96, 34, 34]           --\n",
              "│    └─BasicBlock: 2-16                  [1, 96, 34, 34]           --\n",
              "│    │    └─Sequential: 3-27             [1, 96, 34, 34]           41,760\n",
              "│    │    └─Sequential: 3-28             [1, 96, 34, 34]           83,232\n",
              "│    │    └─Sequential: 3-29             [1, 96, 34, 34]           4,800\n",
              "│    └─BasicBlock: 2-17                  [1, 96, 34, 34]           --\n",
              "│    │    └─Sequential: 3-30             [1, 96, 34, 34]           83,232\n",
              "│    │    └─Sequential: 3-31             [1, 96, 34, 34]           83,232\n",
              "│    └─BasicBlock: 2-18                  [1, 96, 34, 34]           --\n",
              "│    │    └─Sequential: 3-32             [1, 96, 34, 34]           83,232\n",
              "│    │    └─Sequential: 3-33             [1, 96, 34, 34]           83,232\n",
              "│    └─BasicBlock: 2-19                  [1, 96, 34, 34]           --\n",
              "│    │    └─Sequential: 3-34             [1, 96, 34, 34]           83,232\n",
              "│    │    └─Sequential: 3-35             [1, 96, 34, 34]           83,232\n",
              "├─AdaptiveMaxPool2d: 1-7                 [1, 96, 1, 1]             --\n",
              "├─Linear: 1-8                            [1, 48]                   5,232\n",
              "==========================================================================================\n",
              "Total params: 843,396\n",
              "Trainable params: 843,396\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 1.14\n",
              "==========================================================================================\n",
              "Input size (MB): 0.79\n",
              "Forward/backward pass size (MB): 49.78\n",
              "Params size (MB): 3.37\n",
              "Estimated Total Size (MB): 53.94\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hrv_input_size = (1, 12, 224, 224)  # For example: batch size of 1, 12 channels, 224x224 height and width\n",
        "pv_input_size = (1, 1, 224, 224)    # For example: batch size of 1, 1 channel, 224x224 height and width\n",
        "\n",
        "# You need to provide the sizes in a list if your model expects multiple inputs\n",
        "model_input_sizes = [hrv_input_size, pv_input_size]\n",
        "\n",
        "# Use torchinfo's summary function\n",
        "# The input size is passed as a list of tuples, each corresponding to the size of an input the model expects\n",
        "summary(model_light_deep_res, input_size=[(1, 12), (1, 12, 128, 128)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "G33ZLj1vXoLX"
      },
      "outputs": [],
      "source": [
        "# Import the model defined in `submission/model.py`\n",
        "\n",
        "from submission.model import Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Summarises the model created above, used to sense check that the data we are passing through is correct and shows the overall structure of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce51VGYWXoLX"
      },
      "source": [
        "## Training models\n",
        "This generates weights for the model that we can then use for validation. The weights are then saved as the model submission meaning that each time we generate weights we can then save the weights along with the associated model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "id": "7Sxy8PBcXoLX"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32#This controls the number of sites that predictions are made for I think\n",
        "#these are used to load in the data based on the previously defined functions above, the above functions can be altered to change how the data is ingested\n",
        "dataset = ChallengeDataset_inc(pv_inc, hrv, site_locations=site_locations)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, pin_memory=True)#change this to alter which type of data is being loaded in"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "RMSE criterion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "        \n",
        "    def forward(self, predicted, actual):\n",
        "        return torch.sqrt(self.mse(predicted, actual))\n",
        "\n",
        "criterion = RMSELoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the lighter weight resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = model_light_res\n",
        "criterion = RMSELoss()#nn.L1Loss()#Here we are defining the test stat as MAE\n",
        "optimiser = optim.Adam(model.parameters(), lr=1e-3)#Here we are defining the optimiser in this case it is ADAM "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the lightweight deeper resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = model_light_deep_res\n",
        "criterion = RMSELoss()#nn.L1Loss()#Here we are defining the test stat as MAE\n",
        "optimiser = optim.Adam(model.parameters(), lr=1e-3)#Here we are defining the optimiser in this case it is ADAM "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the angle of solar incidence model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {},
      "outputs": [],
      "source": [
        "#For the inc model\n",
        "model = model_light_res_inc\n",
        "criterion = RMSELoss()#nn.L1Loss()#Here we are defining the test stat as MAE\n",
        "optimiser = optim.Adam(model.parameters(), lr=1e-3)#Here we are defining the optimiser in this case it is ADAM "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x1b995fab7f0>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.autograd.set_detect_anomaly(True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "id": "MzuKbgHuXoLX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 12, 2])\n",
            "torch.Size([32, 48])\n",
            "Epoch 1, 200: 0.4308984477818012\n",
            "Epoch 1: 0.3323034445503985\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 1\n",
        "batch_losses = []\n",
        "val_losses = []\n",
        "epoch_train_losses = []\n",
        "epoch_val_losses = []\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0.0##sets the starting loss at zero\n",
        "    count = 0#is used to keep track of the number of batches passed through the training model\n",
        "    print(pv_features.shape)\n",
        "    print(pv_targets.shape)\n",
        "    for i, (pv_features, hrv_features, pv_targets) in enumerate(dataloader): \n",
        "        \n",
        "        optimiser.zero_grad()#resets the gradient of all the previous weights and biases used in the model, can be changed to alter the type of optimiser we use\n",
        "\n",
        "        predictions = model(\n",
        "            pv_features.to(device, dtype=torch.float),\n",
        "            hrv_features.to(device, dtype=torch.float),\n",
        "        )#makes predictions based off of current batch of hrv and pv inputs\n",
        "\n",
        "        loss = criterion(predictions, pv_targets.to(device, dtype=torch.float))#calculates the loss between the models predictions and the actual pv\n",
        "        loss.backward()#backprops the loss\n",
        "\n",
        "        optimiser.step()#updates the parameters based on the calculated loss\n",
        "        ###for generating the training and test loss graph\n",
        "        running_loss += loss.item() * pv_targets.size(0)\n",
        "        count += pv_targets.size(0)\n",
        "        optimiser.step()\n",
        "        \n",
        "        size = int(pv_targets.size(0))#calculates the size of the first dimension of the pv_targets tensor  to determine how many data points are in the current tensor\n",
        "        running_loss += float(loss) * size\n",
        "        count += size\n",
        "        #print(count)\n",
        "        #prints the current training loss for the first 200 data points of 32 batches, then prints again once the next 200 have been computed\n",
        "        if i % 200 == 199:\n",
        "            print(f\"Epoch {epoch + 1}, {i + 1}: {running_loss / count}\")\n",
        "    epoch_train_loss = running_loss / count\n",
        "    epoch_train_losses.append(epoch_train_loss)        \n",
        "    print(f\"Epoch {epoch + 1}: {running_loss / count}\")\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"submission/model.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Saved version for MAE criterion "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EPOCHS = 1\n",
        "batch_losses = []\n",
        "val_losses = []\n",
        "epoch_train_losses = []\n",
        "epoch_val_losses = []\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0.0##sets the starting loss at zero\n",
        "    count = 0#is used to keep track of the number of batches passed through the training model\n",
        "    for i, (pv_features, hrv_features, pv_targets) in enumerate(dataloader): \n",
        "        \n",
        "        optimiser.zero_grad()#resets the gradient of all the previous weights and biases used in the model, can be changed to alter the type of optimiser we use\n",
        "\n",
        "        predictions = model(\n",
        "            pv_features.to(device, dtype=torch.float),\n",
        "            hrv_features.to(device, dtype=torch.float),\n",
        "        )#makes predictions based off of current batch of hrv and pv inputs\n",
        "\n",
        "        loss = criterion(predictions, pv_targets.to(device, dtype=torch.float))#calculates the loss between the models predictions and the actual pv\n",
        "        loss.backward()#backprops the loss\n",
        "\n",
        "        optimiser.step()#updates the parameters based on the calculated loss\n",
        "        ###for generating the training and test loss graph\n",
        "        running_loss += loss.item() * pv_targets.size(0)\n",
        "        count += pv_targets.size(0)\n",
        "        \n",
        "        size = int(pv_targets.size(0))#calculates the size of the first dimension of the pv_targets tensor  to determine how many data points are in the current tensor\n",
        "        running_loss += float(loss) * size\n",
        "        count += size\n",
        "        #print(count)\n",
        "        #prints the current training loss for the first 200 data points of 32 batches, then prints again once the next 200 have been computed\n",
        "        if i % 200 == 199:\n",
        "            print(f\"Epoch {epoch + 1}, {i + 1}: {running_loss / count}\")\n",
        "    epoch_train_loss = running_loss / count\n",
        "    epoch_train_losses.append(epoch_train_loss)        \n",
        "    print(f\"Epoch {epoch + 1}: {running_loss / count}\")\n",
        "    \n",
        "    "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
