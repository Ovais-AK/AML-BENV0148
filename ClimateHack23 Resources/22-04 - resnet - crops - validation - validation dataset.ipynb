{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6ExjmoPXoLU"
      },
      "source": [
        "## Importing packages\n",
        "\n",
        "Here, we import a number of packages we will need to train our first model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pvlib\n",
            "  Downloading pvlib-0.10.4-py3-none-any.whl (29.5 MB)\n",
            "     --------------------------------------- 29.5/29.5 MB 10.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: requests in c:\\users\\james\\anaconda3\\lib\\site-packages (from pvlib) (2.31.0)\n",
            "Requirement already satisfied: pytz in c:\\users\\james\\anaconda3\\lib\\site-packages (from pvlib) (2022.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\james\\anaconda3\\lib\\site-packages (from pvlib) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from pvlib) (1.13.0)\n",
            "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from pvlib) (2.2.1)\n",
            "Requirement already satisfied: h5py in c:\\users\\james\\anaconda3\\lib\\site-packages (from pvlib) (3.10.0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\james\\anaconda3\\lib\\site-packages (from pandas>=1.3.0->pvlib) (2024.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\james\\anaconda3\\lib\\site-packages (from pandas>=1.3.0->pvlib) (2.8.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\james\\anaconda3\\lib\\site-packages (from requests->pvlib) (1.26.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\james\\anaconda3\\lib\\site-packages (from requests->pvlib) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\james\\anaconda3\\lib\\site-packages (from requests->pvlib) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\james\\anaconda3\\lib\\site-packages (from requests->pvlib) (2023.5.7)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\james\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->pvlib) (1.16.0)\n",
            "Installing collected packages: pvlib\n",
            "Successfully installed pvlib-0.10.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\james\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\james\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\james\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\james\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\james\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\james\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\james\\anaconda3\\lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "!pip install pvlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3F_1sE0rXoLU"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\james\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
            "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
            "c:\\Users\\james\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
            "  from pandas.core import (\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from datetime import datetime, time, timedelta\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import xarray as xr\n",
        "from ocf_blosc2 import Blosc2\n",
        "from torch.utils.data import DataLoader, IterableDataset\n",
        "from torchinfo import summary\n",
        "import json\n",
        "import geopandas as gpd\n",
        "import seaborn as sns\n",
        "from scipy.ndimage import zoom\n",
        "import numpy as np\n",
        "import h5py\n",
        "import pvlib \n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (20, 12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run this block to install all data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRDvMchFXoLU",
        "outputId": "1ff0eb44-3f42-471b-8af2-3a9fb4f32ded"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "device\n",
        "if not os.path.exists(\"submission\"):\n",
        "     os.makedirs(\"submission\", exist_ok=True)\n",
        "     #Installing locally means you do not need to rerun this each time you restart the notebook\n",
        "     !curl -L https://raw.githubusercontent.com/climatehackai/getting-started-2023/main/submission/competition.py --output submission/competition.py\n",
        "     !curl -L https://raw.githubusercontent.com/climatehackai/getting-started-2023/main/submission/doxa.yaml --output submission/doxa.yaml\n",
        "     !curl -L https://raw.githubusercontent.com/climatehackai/getting-started-2023/main/submission/model.py --output submission/model.py\n",
        "     !curl -L https://raw.githubusercontent.com/climatehackai/getting-started-2023/main/submission/run.py --output submission/run.py\n",
        "     !curl -L https://raw.githubusercontent.com/climatehackai/getting-started-2023/main/indices.json --output indices.json\n",
        "if not os.path.exists(\"data\"):\n",
        "    os.makedirs(\"data/pv/2020\", exist_ok=True)\n",
        "    os.makedirs(\"data/satellite-hrv/2020\", exist_ok=True)\n",
        "\n",
        "    !curl -L https://huggingface.co/datasets/climatehackai/climatehackai-2023/resolve/main/pv/metadata.csv --output data/pv/metadata.csv\n",
        "    !curl -L https://huggingface.co/datasets/climatehackai/climatehackai-2023/resolve/main/pv/2020/7.parquet --output data/pv/2020/7.parquet\n",
        "    !curl -L https://huggingface.co/datasets/climatehackai/climatehackai-2023/resolve/main/satellite-hrv/2020/7.zarr.zip --output data/satellite-hrv/2020/7.zarr.zip\n",
        "pv = pd.read_parquet(\"data/pv/2020/7.parquet\").drop(\"generation_wh\", axis=1)\n",
        "pv.index = pv.index.set_levels([pv.index.levels[0].tz_localize(None), pv.index.levels[1]])\n",
        "\n",
        "#The parquet data here is similar to a dataframe. The \"power\" is the column with the other data types being indexes. The data is shaped with each timestamp being its own sub frame with the sites having their corresponding power (I think this is the % of their total possible yield).  \n",
        "hrv = xr.open_dataset(\n",
        "    \"data/satellite-hrv/2020/7.zarr.zip\", engine=\"zarr\", chunks=\"auto\"\n",
        ")\n",
        "#The way that this works is that it stores the image as a vector. The vectors are stored as an array of vectors. These then have a timestamp, as we only have one channel the array is a 1D set of vectors with the dimension being time. Read this to help you understand how this is being stored https://tutorial.xarray.dev/fundamentals/01_datastructures.html\n",
        "# To access I have included some examples below\n",
        "#The float value (float16-float64) shows the precision with which data is stored. Later on it is important to make sure that when you are feeding in data into the model that the float type matches between data types, this currently is not a problem when only using the HRV data. I am not yet sure if this will be a problem when using the NWP data.\n",
        "with open(\"indices.json\") as f:\n",
        "    site_locations = {\n",
        "        data_source: {\n",
        "            int(site): (int(location[0]), int(location[1]))\n",
        "            for site, location in locations.items()\n",
        "        }\n",
        "        for data_source, locations in json.load(f).items()\n",
        "    }\n",
        "if not os.path.exists(\"data\"):\n",
        "    os.makedirs(\"data/pv/2020\", exist_ok=True)\n",
        "    os.makedirs(\"data/satellite-hrv/2020\", exist_ok=True)\n",
        "\n",
        "    !curl -L https://huggingface.co/datasets/climatehackai/climatehackai-2023/resolve/main/pv/metadata.csv --output data/pv/metadata.csv\n",
        "    !curl -L https://huggingface.co/datasets/climatehackai/climatehackai-2023/resolve/main/pv/2020/7.parquet --output data/pv/2020/7.parquet\n",
        "    !curl -L https://huggingface.co/datasets/climatehackai/climatehackai-2023/resolve/main/satellite-hrv/2020/7.zarr.zip --output data/satellite-hrv/2020/7.zarr.zip "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## For generating the angle of solar incidence  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>ss_id</th>\n",
              "      <th>power</th>\n",
              "      <th>latitude_rounded</th>\n",
              "      <th>longitude_rounded</th>\n",
              "      <th>orientation</th>\n",
              "      <th>tilt</th>\n",
              "      <th>altitude</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-07-01 00:00:00</td>\n",
              "      <td>2607</td>\n",
              "      <td>0.0</td>\n",
              "      <td>52.44</td>\n",
              "      <td>-0.12</td>\n",
              "      <td>200.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-07-01 00:00:00</td>\n",
              "      <td>2626</td>\n",
              "      <td>0.0</td>\n",
              "      <td>54.99</td>\n",
              "      <td>-3.18</td>\n",
              "      <td>270.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-07-01 00:00:00</td>\n",
              "      <td>2631</td>\n",
              "      <td>0.0</td>\n",
              "      <td>51.81</td>\n",
              "      <td>-2.50</td>\n",
              "      <td>130.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-07-01 00:00:00</td>\n",
              "      <td>2657</td>\n",
              "      <td>0.0</td>\n",
              "      <td>51.49</td>\n",
              "      <td>0.36</td>\n",
              "      <td>185.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-07-01 00:00:00</td>\n",
              "      <td>2729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>51.61</td>\n",
              "      <td>-0.24</td>\n",
              "      <td>180.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6039341</th>\n",
              "      <td>2020-07-31 23:55:00</td>\n",
              "      <td>18873</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53.59</td>\n",
              "      <td>-3.04</td>\n",
              "      <td>290.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6039342</th>\n",
              "      <td>2020-07-31 23:55:00</td>\n",
              "      <td>18989</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53.55</td>\n",
              "      <td>-2.23</td>\n",
              "      <td>207.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6039343</th>\n",
              "      <td>2020-07-31 23:55:00</td>\n",
              "      <td>18990</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53.76</td>\n",
              "      <td>-1.52</td>\n",
              "      <td>180.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6039344</th>\n",
              "      <td>2020-07-31 23:55:00</td>\n",
              "      <td>22335</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53.10</td>\n",
              "      <td>-2.04</td>\n",
              "      <td>140.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6039345</th>\n",
              "      <td>2020-07-31 23:55:00</td>\n",
              "      <td>23083</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53.06</td>\n",
              "      <td>-2.98</td>\n",
              "      <td>120.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6039346 rows Ã— 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  timestamp  ss_id  power  latitude_rounded  \\\n",
              "0       2020-07-01 00:00:00   2607    0.0             52.44   \n",
              "1       2020-07-01 00:00:00   2626    0.0             54.99   \n",
              "2       2020-07-01 00:00:00   2631    0.0             51.81   \n",
              "3       2020-07-01 00:00:00   2657    0.0             51.49   \n",
              "4       2020-07-01 00:00:00   2729    0.0             51.61   \n",
              "...                     ...    ...    ...               ...   \n",
              "6039341 2020-07-31 23:55:00  18873    0.0             53.59   \n",
              "6039342 2020-07-31 23:55:00  18989    0.0             53.55   \n",
              "6039343 2020-07-31 23:55:00  18990    0.0             53.76   \n",
              "6039344 2020-07-31 23:55:00  22335    0.0             53.10   \n",
              "6039345 2020-07-31 23:55:00  23083    0.0             53.06   \n",
              "\n",
              "         longitude_rounded  orientation  tilt  altitude  \n",
              "0                    -0.12        200.0  35.0         0  \n",
              "1                    -3.18        270.0  22.0         0  \n",
              "2                    -2.50        130.0  30.0         0  \n",
              "3                     0.36        185.0  47.0         0  \n",
              "4                    -0.24        180.0  45.0         0  \n",
              "...                    ...          ...   ...       ...  \n",
              "6039341              -3.04        290.0  35.0         0  \n",
              "6039342              -2.23        207.0  35.0         0  \n",
              "6039343              -1.52        180.0  34.0         0  \n",
              "6039344              -2.04        140.0  21.0         0  \n",
              "6039345              -2.98        120.0  31.0         0  \n",
              "\n",
              "[6039346 rows x 8 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#this block finds the long and lat for the sites where it is available \n",
        "pv_ss_id = pv.index.get_level_values(\"ss_id\").unique()\n",
        "pv_ss_time = pv.index.get_level_values(\"timestamp\")\n",
        "pv_meta = pd.read_csv(\"data/pv/metadata.csv\")\n",
        "pv_meta_ssid = pv_meta.ss_id\n",
        "shared_id = [x for x in pv_ss_id if x in pv_meta_ssid]\n",
        "pv_shared = pv_meta[pv_meta[\"ss_id\"].isin(shared_id)] #shared location data, only 698 of 908 sites in the pv file have long and lat for plotting\n",
        "\n",
        "#Merges \n",
        "pv_shared_merge = pv_shared[[\"ss_id\", \"latitude_rounded\", \"longitude_rounded\", \"orientation\", \"tilt\"]]\n",
        "pv_reset = pv.reset_index()\n",
        "\n",
        "pv_az = pd.merge(pv_reset, pv_shared_merge[['ss_id', 'latitude_rounded', 'longitude_rounded', \"orientation\", \"tilt\"]], on='ss_id', how='left').dropna().set_index([\"timestamp\", \"ss_id\"])\n",
        "pv_az[\"altitude\"] = 0\n",
        "pv_az_pre = pv_az.reset_index()\n",
        "\n",
        "#Calculates the azimuth\n",
        "tz = 'Europe/London'\n",
        "location_data = {\n",
        "    'latitude': pv_az_pre['latitude_rounded'].mean(),  # Using mean latitude and longitude\n",
        "    'longitude': pv_az_pre['longitude_rounded'].mean(),\n",
        "    'altitude': pv_az_pre['altitude'].mean()  # You may want to adjust how you handle altitude\n",
        "}\n",
        "\n",
        "# Convert timestamps from UTC to the UK timezone and sort\n",
        "pv_az_pre['timestamp'] = pd.to_datetime(pv_az_pre['timestamp'], utc=True).dt.tz_convert(tz)\n",
        "\n",
        "# Create a single location object\n",
        "location = pvlib.location.Location(location_data['latitude'], location_data['longitude'], tz, location_data['altitude'])\n",
        "\n",
        "# Calculate solar position for all times at once\n",
        "solar_position = location.get_solarposition(pv_az_pre['timestamp'])\n",
        "\n",
        "# Assign the azimuth values directly\n",
        "pv_az_pre['solar_azimuth'] = solar_position['azimuth'].values\n",
        "pv_az_pre['solar_azimuth_south'] = (pv_az_pre['solar_azimuth'] - 180) % 360#check to the see if this is generating the correct angle \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Calculates the solar zenith and then converts required values to radians\n",
        "tz = 'Europe/London'\n",
        "location_data = {\n",
        "    'latitude': pv_az_pre['latitude_rounded'].mean(),\n",
        "    'longitude': pv_az_pre['longitude_rounded'].mean(),\n",
        "    'altitude': pv_az_pre['altitude'].mean()\n",
        "}\n",
        "\n",
        "# Convert timestamps from UTC to the UK timezone and sort\n",
        "pv_az_pre['timestamp'] = pd.to_datetime(pv_az_pre['timestamp'], utc=True).dt.tz_convert(tz)\n",
        "\n",
        "# Create a single location object\n",
        "location = pvlib.location.Location(\n",
        "    location_data['latitude'], \n",
        "    location_data['longitude'], \n",
        "    tz, \n",
        "    location_data['altitude']\n",
        ")\n",
        "solar_position = location.get_solarposition(pv_az_pre['timestamp'])\n",
        "pv_az_pre['solar_zenith'] = 90 - solar_position['elevation'].values#where does this come from?\n",
        "\n",
        "\n",
        "pv_az_pre['solar_azimuth_radians'] = np.radians(pv_az_pre['solar_azimuth'])\n",
        "pv_az_pre['solar_azimuth_south_radians'] = np.radians(pv_az_pre['solar_azimuth_south'])\n",
        "\n",
        "pv_az_pre['solar_zenith_radians'] = np.radians(pv_az_pre['solar_zenith'])\n",
        "pv_az_pre[\"tilt_radians\"] = np.radians(pv_az_pre['tilt'])\n",
        "pv_az_pre[\"latitude_rounded_radians\"] = np.radians(pv_az_pre['latitude_rounded'])\n",
        "pv_az_pre[\"longitude_rounded_radians\"] = np.radians(pv_az_pre['longitude_rounded'])\n",
        "pv_az_pre[\"orientation_radians\"] = np.radians(pv_az_pre['orientation'])\n",
        "\n",
        "pv_az_pre['timestamp'] = pv_az_pre['timestamp'].dt.tz_convert('UTC')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "cos_theta_inc = (\n",
        "    np.sin(pv_az_pre['latitude_rounded_radians']) * np.cos(pv_az_pre['solar_zenith_radians']) * np.cos(pv_az_pre['tilt_radians']) +\n",
        "    np.sin(pv_az_pre['solar_zenith_radians']) * np.cos(pv_az_pre['latitude_rounded_radians']) * np.sin(pv_az_pre['tilt_radians']) * np.cos(pv_az_pre['orientation_radians'] - pv_az_pre['solar_azimuth_south_radians']) +\n",
        "    np.cos(pv_az_pre['solar_zenith_radians']) * np.sin(pv_az_pre['tilt_radians']) * np.sin(pv_az_pre['orientation_radians'] - pv_az_pre['solar_azimuth_south_radians'])\n",
        ")\n",
        "cos_theta_inc = np.clip(cos_theta_inc, -1.0, 1.0)\n",
        "\n",
        "pv_az_pre['angle_of_incidence_radians'] = np.arccos(cos_theta_inc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "pv_inc = pv_az_pre.drop(columns={'latitude_rounded', 'longitude_rounded',\n",
        "       'orientation', 'tilt', 'altitude', 'solar_azimuth',\n",
        "       'solar_azimuth_radians', 'solar_zenith', 'solar_zenith_radians',\n",
        "       'tilt_radians', 'latitude_rounded_radians', 'longitude_rounded_radians',\n",
        "       'orientation_radians', \"solar_azimuth_south\", \"solar_azimuth_south_radians\"}).sort_values([ \"timestamp\"]).set_index([\"timestamp\", \"ss_id\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "pv_inc_chk = pv_inc.reset_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Getting final outputs for the pv_inc and formatting them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pv_inc.reset_index()\n",
        "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
        "pv_inc = df.set_index([\"timestamp\", \"ss_id\"])\n",
        "\n",
        "pv_inc.index = pv_inc.index.set_levels([pv_inc.index.levels[0].tz_localize(None), pv_inc.index.levels[1]])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nomralising power and angle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [],
      "source": [
        "pv_norm = pv_inc\n",
        "\n",
        "power_min = pv_norm['power'].min()\n",
        "power_range = pv_norm['power'].max() - power_min\n",
        "pv_norm['power_normalized'] = (pv_norm['power'] - power_min) / power_range\n",
        "\n",
        "# Normalize the 'angle_of_incidence_radians' column\n",
        "angle_min = pv_norm['angle_of_incidence_radians'].min()\n",
        "angle_range = pv_norm['angle_of_incidence_radians'].max() - angle_min\n",
        "pv_norm['angle_of_incidence_radians_normalized'] = (pv_norm['angle_of_incidence_radians'] - angle_min) / angle_range\n",
        "\n",
        "pv_inc =pv_norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\"For a deep learning model like a ResNet, standardization is commonly used because it generally makes training less sensitive to the scale of features and their values. Neural networks often perform better with standardized inputs, especially in the deeper layers.\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {},
      "outputs": [],
      "source": [
        "pv_inc.to_csv(\"pv_inc_2020_07.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "pv_inc = pd.read_csv(\"pv_inc_2020_07.csv\")\n",
        "pv_inc = pv_inc.set_index([\"timestamp\", \"ss_id\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1x1 crop loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "#This function extracts the area around each individual site using the PV dicts pixel based (as in the location of sites are determined by their pixel in the image) location and then extracts an area around each site. These areas are combined, based on their timestamp,\n",
        "#with the HRV data that then has its satellite imagery data extracted. This implies that the model is using subsets of the satellite imagery to train the model to make predictions for each site rather than using the whole image and then \"learning\" where the sites are.\n",
        "\n",
        "class ChallengeDataset_crop1(IterableDataset):#This function sets up the data so that it can be iterated through by the CNN\n",
        "    def __init__(self, pv, hrv, site_locations, start_date = \"2020-7-1\", end_date = \"2020-7-30\", sites=None):#The \"self\" augmentation here is used to use create a shared class between the different data types that are then iterable based on their shared timestamp\n",
        "        self.pv = pv\n",
        "        self.hrv = hrv\n",
        "        self._site_locations = site_locations\n",
        "        self._sites = sites if sites else list(site_locations[\"hrv\"].keys())#This gets the individual site ids which are stored as the dict's keys\n",
        "        self.start_date = list(map(int, start_date.split(\"-\")))\n",
        "        self.end_date= list(map(int, end_date.split(\"-\")))\n",
        "\n",
        "    def _get_image_times(self):#This function starts at the minimum date in the set and iterates up to the highest date, this is done as the data set is large and due to the nature of the parquette and xarray\n",
        "        min_date = datetime(self.start_date[0], self.start_date[1], self.start_date[2])\n",
        "        max_date = datetime(self.end_date[0], self.end_date[1], self.end_date[2])\n",
        "        #max and min need to be changed if we use more than one month of data\n",
        "        start_time = time(8)\n",
        "        end_time = time(17)\n",
        "\n",
        "        date = min_date#starts at the first timestamp\n",
        "        while date <= max_date: #iterates through up to the max\n",
        "            current_time = datetime.combine(date, start_time)\n",
        "            while current_time.time() < end_time:\n",
        "                if current_time:\n",
        "                    yield current_time\n",
        "\n",
        "                current_time += timedelta(minutes=60)\n",
        "\n",
        "            date += timedelta(days=1)\n",
        "\n",
        "    def __iter__(self):\n",
        "        for time in self._get_image_times():\n",
        "            time_ids = pd.date_range(start=time + timedelta(hours=1),\n",
        "                                     end=time + timedelta(hours=5) - timedelta(minutes=5),\n",
        "                                     freq='5min')\n",
        "            time_ids = time_ids.strftime('%Y-%m-%dT%H:%M:%S').tolist()        \n",
        "            first_hour = slice(str(time), str(time + timedelta(minutes=55)))#gets the time and then uses this to select the corresponding time from the pv set  \n",
        "\n",
        "            pv_features = pv.xs(first_hour, drop_level=False)  # this gets the pv yield of the current timestamp selected earlier\n",
        "            pv_targets = pv.xs(\n",
        "                slice(  # type: ignore\n",
        "                    str(time + timedelta(hours=1)),\n",
        "                    str(time + timedelta(hours=4, minutes=55)),\n",
        "                ),\n",
        "                drop_level=False,\n",
        "            )#pv targets defines the time span over which we are trying to make pv yield predictions\n",
        "            #print( pv_features)\n",
        "            #print(pv_features)\n",
        "\n",
        "            hrv_data = self.hrv[\"data\"].sel(time=first_hour).to_numpy()#gets the hrv satellite image that is associated with the first hour timestamp setting it up as an input feature\n",
        "\n",
        "            for site in self._sites:\n",
        "                site_id = site\n",
        "                try:\n",
        "                    # Get solar PV features and targets, the site_targets is used to find the models loss\n",
        "                    site_features = pv_features.xs(site, level=1).to_numpy().squeeze(-1)#gets the pixel based location of the pv site and then uses this to make predictions based on the individual sites\n",
        "                    site_targets = pv_targets.xs(site, level=1).to_numpy().squeeze(-1)\n",
        "                    assert site_features.shape == (12,) and site_targets.shape == (48,)#compresses the data from N dimensions to 12 and 48 respectively\n",
        "                    #print(site)\n",
        "                    # Get a 128x128 HRV crop centred on the site over the previous hour\n",
        "                    x, y = self._site_locations[\"hrv\"][site]#gets the location of the site based on the pv sites pixel level location\n",
        "                    hrv_features = hrv_data[:, y  : y + 1, x  : x + 1, 0]\n",
        "                    assert hrv_features.shape == (12, 1, 1)#crops the image to be be 128x128 around the site\n",
        "                    #asset is used to force the dimensions of the extracted site level image to be the same\n",
        "                    # How might you adapt this for the non-HRV, weather and aerosol data?\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "                yield  time_ids, site_id, site_features, hrv_features, site_targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Solar inci loader 6 x 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#hrv_features = hrv_data[:, y - 3 : y + 3, x - 3 : x + 3, 0]\n",
        "                  #  assert hrv_features.shape == (12, 6, 6)#crops the image to be be 128x128 around the site"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#hrv_features = hrv_data[:, y  : y + 1, x  : x + 1, 0]\n",
        "                 #   assert hrv_features.shape == (12, 1, 1)#crops the image to be be 128x128 around the site"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Solar angle data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "#This function extracts the area around each individual site using the PV dicts pixel based (as in the location of sites are determined by their pixel in the image) location and then extracts an area around each site. These areas are combined, based on their timestamp,\n",
        "#with the HRV data that then has its satellite imagery data extracted. This implies that the model is using subsets of the satellite imagery to train the model to make predictions for each site rather than using the whole image and then \"learning\" where the sites are.\n",
        "\n",
        "class ChallengeDataset_inc(IterableDataset):#This function sets up the data so that it can be iterated through by the CNN\n",
        "    def __init__(self, pv_inc, hrv, site_locations, start_date = \"2020-7-1\", end_date = \"2020-7-30\", sites=None):#The \"self\" augmentation here is used to use create a shared class between the different data types that are then iterable based on their shared timestamp\n",
        "        self.pv_inc = pv_inc\n",
        "        self.hrv = hrv\n",
        "        self._site_locations = site_locations\n",
        "        self._sites = sites if sites else list(site_locations[\"hrv\"].keys())#This gets the individual site ids which are stored as the dict's keys\n",
        "        self.start_date = list(map(int, start_date.split(\"-\")))\n",
        "        self.end_date= list(map(int, end_date.split(\"-\")))\n",
        "\n",
        "    def _get_image_times(self):#This function starts at the minimum date in the set and iterates up to the highest date, this is done as the data set is large and due to the nature of the parquette and xarray\n",
        "        min_date = datetime(self.start_date[0], self.start_date[1], self.start_date[2])\n",
        "        max_date = datetime(self.end_date[0], self.end_date[1], self.end_date[2])\n",
        "        #max and min need to be changed if we use more than one month of data\n",
        "        start_time = time(8)\n",
        "        end_time = time(17)\n",
        "\n",
        "        date = min_date#starts at the first timestamp\n",
        "        while date <= max_date: #iterates through up to the max\n",
        "            current_time = datetime.combine(date, start_time)\n",
        "            while current_time.time() < end_time:\n",
        "                if current_time:\n",
        "                    yield current_time\n",
        "\n",
        "                current_time += timedelta(minutes=60)\n",
        "\n",
        "            date += timedelta(days=1)\n",
        "\n",
        "    def __iter__(self):\n",
        "        for time in self._get_image_times():\n",
        "            time_ids = pd.date_range(start=time + timedelta(hours=1),\n",
        "                                     end=time + timedelta(hours=5) - timedelta(minutes=5),\n",
        "                                     freq='5min')\n",
        "            time_ids = time_ids.strftime('%Y-%m-%dT%H:%M:%S').tolist()    \n",
        "            first_hour = slice(str(time), str(time + timedelta(minutes=55)))#gets the time and then uses this to select the corresponding time from the pv set  \n",
        "            #print(\"Available columns in pv_inc:\", self.pv_inc.columns)\n",
        "           \n",
        "            pv_features = self.pv_inc.xs(first_hour, drop_level=False)[[\"power\", \"angle_of_incidence_radians\"]]\n",
        "\n",
        "        # Fetching PV targets for the future time span\n",
        "            pv_targets = self.pv_inc.xs(\n",
        "                slice(\n",
        "                    str(time + timedelta(hours=1)),  # Start 1 hour after the first_hour\n",
        "                    str(time + timedelta(hours=4, minutes=55)),  # Up to almost 5 hours later\n",
        "                ),\n",
        "                drop_level=False,\n",
        "            )[\"power\"]\n",
        "            #print(\"First hour slice:\", first_hour)\n",
        "            #print(\"Sample data from pv_inc:\", self.pv_inc.xs(first_hour, drop_level=False).head())\n",
        "            #gets the hrv satellite image that is associated with the first hour timestamp setting it up as an input feature\n",
        "            hrv_data = self.hrv['data'].sel(time=first_hour).to_numpy()\n",
        "\n",
        "            for site in self._sites:\n",
        "                site_id = site\n",
        "\n",
        "                try:\n",
        "                    #print(site)\n",
        "                    # Get solar PV features and targets, the site_targets is used to find the models loss\n",
        "                    site_features = pv_features.xs(site, level=1).to_numpy()#.squeeze(-1)#gets the pixel based location of the pv site and then uses this to make predictions based on the individual sites\n",
        "                    \n",
        "                    site_targets = pv_targets.xs(site, level=1).to_numpy()#.squeeze(-1)\n",
        "                    assert site_features.shape == (12,2) and site_targets.shape == (48,)#compresses the data from N dimensions to 12 and 48 respectively\n",
        "                  \n",
        "                    # Get a 128x128 HRV crop centred on the site over the previous hour\n",
        "                    x, y = self._site_locations[\"hrv\"][site]#gets the location of the site based on the pv sites pixel level location\n",
        "                    hrv_features = hrv_data[:, y - 3 : y + 3, x - 3 : x + 3, 0]\n",
        "                    assert hrv_features.shape == (12, 6, 6)#crops the image to be be 128x128 around the site\n",
        "                    #asset is used to force the dimensions of the extracted site level image to be the same\n",
        "                    # How might you adapt this for the non-HRV, weather and aerosol data?\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "                yield  time_ids, site_id, site_features, hrv_features, site_targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Solar angle model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "layers = [5, 5, 5, 5] #Change this to change the number of layers that you are using, \n",
        "\n",
        "def conv_block(in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
        "    #This section creates a sequence of layers that perform the networks convolution which are applied iteratively in the Resnet_light block\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding), #Feature extraction\n",
        "        nn.BatchNorm2d(out_channels), #Noramlises the outputs from the convolution layers\n",
        "        nn.ReLU(inplace=True)#Applies the activation function\n",
        "    )\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1 \n",
        "    #Applies the convolution established in the previous layer twice giving the F(x) portion of the resnet model\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv_block(in_channels, out_channels, stride=stride)\n",
        "        self.conv2 = conv_block(out_channels, out_channels)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x): #Keeps the x portion of the resnet \n",
        "        identity = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        if self.downsample is not None: #Downsamples the model if needed to match the dimensions of outputs if the identity output does not match the F(x) portion of the output\n",
        "            identity = self.downsample(x)\n",
        "        out = out + identity #Creates the F(x) + x that is then passed to the relu activation function between the resnet conv layers\n",
        "        return F.relu(out, inplace=False)  #Relu applied to combined results, \n",
        "\n",
        "class ResNet_light_inc(nn.Module):\n",
        "    #This class stacks the multiple basic blocks set up in the previous functions\n",
        "    def __init__(self, block, layers):\n",
        "        #I Think we can reduce the number of layers here as the model is applied four convolutions to generate F(x), the resnet paper uses two.\n",
        "        super(ResNet_light_inc, self).__init__()\n",
        "        self.in_channels = 12 #reduce the stride\n",
        "        self.initial = conv_block(12, 12, kernel_size=2, stride=1, padding=3)#Applies the initial convolution \n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2, padding=1)#Runs maxpool convolution\n",
        "        self.layer1 = self._make_layer(block, 12, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 24, layers[1], stride=1)\n",
        "        self.layer3 = self._make_layer(block, 48, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 96, layers[3], stride=1)\n",
        "        self.avgpool = nn.AdaptiveMaxPool2d((1, 1))#Forces the consistency of output sizes to be 1x1 \n",
        "        # Adjust this linear layer based on the concatenated size of HRV and PV features\n",
        "        self.fc = nn.Linear(96  + 12, 48)  #takes the flatterened output of the conv layers for the 12 hourly time instances and then hands them to 48 different class outputs\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride=1):#Used to stack the multiple layers of the resnet model\n",
        "        downsample = None#This checks to make sure that the stride applied matches between input tensor and the output tensor, I am not completely sure if this changes the dimensions of the output tensor\n",
        "        if stride != 1 or self.in_channels != out_channels * block.expansion:#Expands the number of outputs compared to the inputs, for the BasicBlock typically no expansion is needed. This is still needed for the model to run. \n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * block.expansion),\n",
        "            )\n",
        "        layers = [block(self.in_channels, out_channels, stride, downsample)]#This section creates a series of blocks for the layer\n",
        "        self.in_channels = out_channels * block.expansion #Ensures that after the blocks have been defined the next layer gets the correct number of input channels\n",
        "        for _ in range(1, num_blocks):\n",
        "            layers.append(block(self.in_channels, out_channels))#\n",
        "        return nn.Sequential(*layers)#Stretches the dims of the resnet to match the layers defined above\n",
        "        #Need to clarify exactly what expansion is doing.\n",
        "    def forward(self, pv_inc, hrv ):#Defines how the model passes the outputs through the network\n",
        "        #print(\"Initial HRV shape:\", hrv.shape)  \n",
        "        #print(\"Initial PV shape:\", pv.shape) \n",
        "        #print(f\"{pv[0]}\")\n",
        "        x = self.initial(hrv)#Passes the HRV data through the initial block defined earlier\n",
        "        x = self.maxpool(x)#Downsamples using maxpooling\n",
        "        #print(\"Shape after initial conv and maxpool:\", x.shape)\n",
        "\n",
        "        x = self.layer1(x)#Applies the layers defined above, \n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        #print(\"Shape after ResNet_light blocks:\", x.shape)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        #print(\"Shape after avgpool:\", x.shape)\n",
        "        x = torch.flatten(x, 1)# Applies the flattering to the second dimension as the first dimension is the batch size\n",
        "        pv_inc = torch.flatten(pv_inc, start_dim=1)#take in at the fully connected layer\n",
        "        #print(f\"Sshape of x = {x.shape} shape of pv = {pv.shape}\")\n",
        "        #x = torch.concat((x, pv), dim=-1)\n",
        "        #print(\"Shape after avgpool and flatten:\", x.shape)\n",
        "\n",
        "        #Take in the pc_inc and the pv power as seperate features and run the model again\n",
        "        \n",
        "        #pv = pv.view(pv.size(0), -1)\n",
        "        #Checks to make sure that the pv tensor dimensions match the HRV tensor dimensions\n",
        "        if pv_inc.dim() > 2:\n",
        "            pv_inc = torch.flatten(pv_inc, start_dim=1)\n",
        "        #print(\"Adjusted PV shape:\", pv.shape)\n",
        "\n",
        "        combined = torch.cat((x, pv_inc), dim=1)#Combines the pv and hrv data along the feature dimension\n",
        "\n",
        "        if self.fc.in_features != combined.shape[1]:\n",
        "            self.fc = nn.Linear(combined.shape[1], 48).to(combined.device)\n",
        "            #Above runs a check to make sure that the number of input features is correct\n",
        "        out = self.fc(combined) #takes the combined output of the pv and hrv and passes them to the fully connected layer defined above\n",
        "        return out\n",
        "model_light_res_inc = ResNet_light_inc(BasicBlock, layers).to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test model inc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "layers = [5, 5, 5, 5] #Change this to change the number of layers that you are using, \n",
        "\n",
        "def conv_block(in_channels, out_channels, kernel_size=2, stride=1, padding=0):\n",
        "    #This section creates a sequence of layers that perform the networks convolution which are applied iteratively in the Resnet_light block\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding), #Feature extraction\n",
        "        nn.BatchNorm2d(out_channels), #Noramlises the outputs from the convolution layers\n",
        "        nn.ReLU(inplace=True)#Applies the activation function\n",
        "    )\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1 \n",
        "    #Applies the convolution established in the previous layer twice giving the F(x) portion of the resnet model\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv_block(in_channels, out_channels, stride=stride)\n",
        "        self.conv2 = conv_block(out_channels, out_channels)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x): #Keeps the x portion of the resnet \n",
        "        identity = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        if self.downsample is not None: #Downsamples the model if needed to match the dimensions of outputs if the identity output does not match the F(x) portion of the output\n",
        "            identity = self.downsample(x)\n",
        "        out = out + identity #Creates the F(x) + x that is then passed to the relu activation function between the resnet conv layers\n",
        "        return F.relu(out, inplace=False)  #Relu applied to combined results, \n",
        "\n",
        "class ResNet_light_inc(nn.Module):\n",
        "    #This class stacks the multiple basic blocks set up in the previous functions\n",
        "    def __init__(self, block, layers):\n",
        "        #I Think we can reduce the number of layers here as the model is applied four convolutions to generate F(x), the resnet paper uses two.\n",
        "        super(ResNet_light_inc, self).__init__()\n",
        "        self.in_channels = 12 #reduce the stride\n",
        "        self.initial = conv_block(12, 12, kernel_size=2, stride=1, padding=0)#Applies the initial convolution \n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2, padding=1)#Runs maxpool convolution\n",
        "        self.layer1 = self._make_layer(block, 12, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 24, layers[1], stride=1)\n",
        "        self.layer3 = self._make_layer(block, 48, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 96, layers[3], stride=1)\n",
        "        self.avgpool = nn.AdaptiveMaxPool2d((1, 1))#Forces the consistency of output sizes to be 1x1 \n",
        "        # Adjust this linear layer based on the concatenated size of HRV and PV features\n",
        "        self.fc = nn.Linear(96  + 12, 48)  #takes the flatterened output of the conv layers for the 12 hourly time instances and then hands them to 48 different class outputs\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride=1):#Used to stack the multiple layers of the resnet model\n",
        "        downsample = None#This checks to make sure that the stride applied matches between input tensor and the output tensor, I am not completely sure if this changes the dimensions of the output tensor\n",
        "        if stride != 1 or self.in_channels != out_channels * block.expansion:#Expands the number of outputs compared to the inputs, for the BasicBlock typically no expansion is needed. This is still needed for the model to run. \n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * block.expansion),\n",
        "            )\n",
        "        layers = [block(self.in_channels, out_channels, stride, downsample)]#This section creates a series of blocks for the layer\n",
        "        self.in_channels = out_channels * block.expansion #Ensures that after the blocks have been defined the next layer gets the correct number of input channels\n",
        "        for _ in range(1, num_blocks):\n",
        "            layers.append(block(self.in_channels, out_channels))#\n",
        "        return nn.Sequential(*layers)#Stretches the dims of the resnet to match the layers defined above\n",
        "        #Need to clarify exactly what expansion is doing.\n",
        "    def forward(self, pv_inc, hrv ):#Defines how the model passes the outputs through the network\n",
        "        #print(\"Initial HRV shape:\", hrv.shape)  \n",
        "        #print(\"Initial PV shape:\", pv.shape) \n",
        "        #print(f\"{pv[0]}\")\n",
        "        x = self.initial(hrv)#Passes the HRV data through the initial block defined earlier\n",
        "        x = self.maxpool(x)#Downsamples using maxpooling\n",
        "        #print(\"Shape after initial conv and maxpool:\", x.shape)\n",
        "\n",
        "        x = self.layer1(x)#Applies the layers defined above, \n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        #print(\"Shape after ResNet_light blocks:\", x.shape)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        #print(\"Shape after avgpool:\", x.shape)\n",
        "        x = torch.flatten(x, 1)# Applies the flattering to the second dimension as the first dimension is the batch size\n",
        "        pv_inc = torch.flatten(pv_inc, start_dim=1)#take in at the fully connected layer\n",
        "        #print(f\"Sshape of x = {x.shape} shape of pv = {pv.shape}\")\n",
        "        #x = torch.concat((x, pv), dim=-1)\n",
        "        #print(\"Shape after avgpool and flatten:\", x.shape)\n",
        "\n",
        "        #Take in the pc_inc and the pv power as seperate features and run the model again\n",
        "        \n",
        "        #pv = pv.view(pv.size(0), -1)\n",
        "        #Checks to make sure that the pv tensor dimensions match the HRV tensor dimensions\n",
        "        if pv.dim() > 2:\n",
        "            pv = torch.flatten(pv_inc, start_dim=1)\n",
        "        #print(\"Adjusted PV shape:\", pv.shape)\n",
        "\n",
        "        combined = torch.cat((x, pv_inc), dim=1)#Combines the pv and hrv data along the feature dimension\n",
        "\n",
        "        if self.fc.in_features != combined.shape[1]:\n",
        "            self.fc = nn.Linear(combined.shape[1], 48).to(combined.device)\n",
        "            #Above runs a check to make sure that the number of input features is correct\n",
        "        out = self.fc(combined) #takes the combined output of the pv and hrv and passes them to the fully connected layer defined above\n",
        "        return out\n",
        "model_light_res_inc = ResNet_light_inc(BasicBlock, layers).to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Most up to date version of solar angle model 6 x 6 25 layers\n",
        "adding in solar angle makes the rmse way higher still"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "layers = [5, 5, 5, 5] #Change this to change the number of layers that you are using, \n",
        "\n",
        "def conv_block(in_channels, out_channels, kernel_size=1, stride=1, padding=0):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv_block(in_channels, out_channels, stride=stride)\n",
        "        self.conv2 = conv_block(out_channels, out_channels)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "        out = out + identity\n",
        "        return F.relu(out, inplace=False)\n",
        "\n",
        "class ResNet_light_inc(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers):\n",
        "        super(ResNet_light_inc, self).__init__()\n",
        "        self.in_channels = 12 #reduce the stride\n",
        "        self.initial = conv_block(12, 12, kernel_size=2, stride=1, padding=0)\n",
        "        #self.maxpool = nn.MaxPool2d(kernel_size=1, stride=1, padding=0)\n",
        "        self.layer1 = self._make_layer(block, 12, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 24, layers[1], stride=1)\n",
        "        self.layer3 = self._make_layer(block, 48, layers[2], stride=1)\n",
        "        self.layer4 = self._make_layer(block, 96, layers[3], stride=1)\n",
        "        self.avgpool = nn.AdaptiveMaxPool2d((1, 1))\n",
        "        # Adjust this linear layer based on the concatenated size of HRV and PV features\n",
        "        self.fc = nn.Linear(96  + 12, 48)  \n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * block.expansion),\n",
        "            )\n",
        "        layers = [block(self.in_channels, out_channels, stride, downsample)]\n",
        "        self.in_channels = out_channels * block.expansion\n",
        "        for _ in range(1, num_blocks):\n",
        "            layers.append(block(self.in_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, pv_inc, hrv):\n",
        "        x = self.initial(hrv)\n",
        "        #x = self.maxpool(x)\n",
        "        #print(\"Shape after initial conv and maxpool:\", x.shape)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        #print(\"Shape after ResNet_light blocks:\", x.shape)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        pv_inc = torch.flatten(pv_inc, start_dim=1)\n",
        "        if pv_inc.dim() > 2:\n",
        "            pv_inc = torch.flatten(pv_inc, start_dim=1)\n",
        "        combined = torch.cat((x, pv_inc), dim=1)\n",
        "        #This line might increase computational intensity\n",
        "        if self.fc.in_features != combined.shape[1]:\n",
        "            self.fc = nn.Linear(combined.shape[1], 48).to(combined.device)\n",
        "        out = self.fc(combined)\n",
        "        return out\n",
        "    \n",
        "model_light_res_inc = ResNet_light_inc(BasicBlock, layers).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "ResNet_light_inc                         [1, 48]                   --\n",
              "â”œâ”€Sequential: 1-1                        [1, 12, 5, 5]             --\n",
              "â”‚    â””â”€Conv2d: 2-1                       [1, 12, 5, 5]             588\n",
              "â”‚    â””â”€BatchNorm2d: 2-2                  [1, 12, 5, 5]             24\n",
              "â”‚    â””â”€ReLU: 2-3                         [1, 12, 5, 5]             --\n",
              "â”œâ”€Sequential: 1-2                        [1, 12, 5, 5]             --\n",
              "â”‚    â””â”€BasicBlock: 2-4                   [1, 12, 5, 5]             --\n",
              "â”‚    â”‚    â””â”€Sequential: 3-1              [1, 12, 5, 5]             180\n",
              "â”‚    â”‚    â””â”€Sequential: 3-2              [1, 12, 5, 5]             180\n",
              "â”‚    â””â”€BasicBlock: 2-5                   [1, 12, 5, 5]             --\n",
              "â”‚    â”‚    â””â”€Sequential: 3-3              [1, 12, 5, 5]             180\n",
              "â”‚    â”‚    â””â”€Sequential: 3-4              [1, 12, 5, 5]             180\n",
              "â”‚    â””â”€BasicBlock: 2-6                   [1, 12, 5, 5]             --\n",
              "â”‚    â”‚    â””â”€Sequential: 3-5              [1, 12, 5, 5]             180\n",
              "â”‚    â”‚    â””â”€Sequential: 3-6              [1, 12, 5, 5]             180\n",
              "â”‚    â””â”€BasicBlock: 2-7                   [1, 12, 5, 5]             --\n",
              "â”‚    â”‚    â””â”€Sequential: 3-7              [1, 12, 5, 5]             180\n",
              "â”‚    â”‚    â””â”€Sequential: 3-8              [1, 12, 5, 5]             180\n",
              "â”‚    â””â”€BasicBlock: 2-8                   [1, 12, 5, 5]             --\n",
              "â”‚    â”‚    â””â”€Sequential: 3-9              [1, 12, 5, 5]             180\n",
              "â”‚    â”‚    â””â”€Sequential: 3-10             [1, 12, 5, 5]             180\n",
              "â”œâ”€Sequential: 1-3                        [1, 24, 5, 5]             --\n",
              "â”‚    â””â”€BasicBlock: 2-9                   [1, 24, 5, 5]             --\n",
              "â”‚    â”‚    â””â”€Sequential: 3-11             [1, 24, 5, 5]             360\n",
              "â”‚    â”‚    â””â”€Sequential: 3-12             [1, 24, 5, 5]             648\n",
              "â”‚    â”‚    â””â”€Sequential: 3-13             [1, 24, 5, 5]             336\n",
              "â”‚    â””â”€BasicBlock: 2-10                  [1, 24, 5, 5]             --\n",
              "â”‚    â”‚    â””â”€Sequential: 3-14             [1, 24, 5, 5]             648\n",
              "â”‚    â”‚    â””â”€Sequential: 3-15             [1, 24, 5, 5]             648\n",
              "â”‚    â””â”€BasicBlock: 2-11                  [1, 24, 5, 5]             --\n",
              "â”‚    â”‚    â””â”€Sequential: 3-16             [1, 24, 5, 5]             648\n",
              "â”‚    â”‚    â””â”€Sequential: 3-17             [1, 24, 5, 5]             648\n",
              "â”‚    â””â”€BasicBlock: 2-12                  [1, 24, 5, 5]             --\n",
              "â”‚    â”‚    â””â”€Sequential: 3-18             [1, 24, 5, 5]             648\n",
              "â”‚    â”‚    â””â”€Sequential: 3-19             [1, 24, 5, 5]             648\n",
              "â”‚    â””â”€BasicBlock: 2-13                  [1, 24, 5, 5]             --\n",
              "â”‚    â”‚    â””â”€Sequential: 3-20             [1, 24, 5, 5]             648\n",
              "â”‚    â”‚    â””â”€Sequential: 3-21             [1, 24, 5, 5]             648\n",
              "â”œâ”€Sequential: 1-4                        [1, 48, 5, 5]             --\n",
              "â”‚    â””â”€BasicBlock: 2-14                  [1, 48, 5, 5]             --\n",
              "â”‚    â”‚    â””â”€Sequential: 3-22             [1, 48, 5, 5]             1,296\n",
              "â”‚    â”‚    â””â”€Sequential: 3-23             [1, 48, 5, 5]             2,448\n",
              "â”‚    â”‚    â””â”€Sequential: 3-24             [1, 48, 5, 5]             1,248\n",
              "â”‚    â””â”€BasicBlock: 2-15                  [1, 48, 5, 5]             --\n",
              "â”‚    â”‚    â””â”€Sequential: 3-25             [1, 48, 5, 5]             2,448\n",
              "â”‚    â”‚    â””â”€Sequential: 3-26             [1, 48, 5, 5]             2,448\n",
              "â”‚    â””â”€BasicBlock: 2-16                  [1, 48, 5, 5]             --\n",
              "â”‚    â”‚    â””â”€Sequential: 3-27             [1, 48, 5, 5]             2,448\n",
              "â”‚    â”‚    â””â”€Sequential: 3-28             [1, 48, 5, 5]             2,448\n",
              "â”‚    â””â”€BasicBlock: 2-17                  [1, 48, 5, 5]             --\n",
              "â”‚    â”‚    â””â”€Sequential: 3-29             [1, 48, 5, 5]             2,448\n",
              "â”‚    â”‚    â””â”€Sequential: 3-30             [1, 48, 5, 5]             2,448\n",
              "â”‚    â””â”€BasicBlock: 2-18                  [1, 48, 5, 5]             --\n",
              "â”‚    â”‚    â””â”€Sequential: 3-31             [1, 48, 5, 5]             2,448\n",
              "â”‚    â”‚    â””â”€Sequential: 3-32             [1, 48, 5, 5]             2,448\n",
              "â”œâ”€Sequential: 1-5                        [1, 96, 5, 5]             --\n",
              "â”‚    â””â”€BasicBlock: 2-19                  [1, 96, 5, 5]             --\n",
              "â”‚    â”‚    â””â”€Sequential: 3-33             [1, 96, 5, 5]             4,896\n",
              "â”‚    â”‚    â””â”€Sequential: 3-34             [1, 96, 5, 5]             9,504\n",
              "â”‚    â”‚    â””â”€Sequential: 3-35             [1, 96, 5, 5]             4,800\n",
              "â”‚    â””â”€BasicBlock: 2-20                  [1, 96, 5, 5]             --\n",
              "â”‚    â”‚    â””â”€Sequential: 3-36             [1, 96, 5, 5]             9,504\n",
              "â”‚    â”‚    â””â”€Sequential: 3-37             [1, 96, 5, 5]             9,504\n",
              "â”‚    â””â”€BasicBlock: 2-21                  [1, 96, 5, 5]             --\n",
              "â”‚    â”‚    â””â”€Sequential: 3-38             [1, 96, 5, 5]             9,504\n",
              "â”‚    â”‚    â””â”€Sequential: 3-39             [1, 96, 5, 5]             9,504\n",
              "â”‚    â””â”€BasicBlock: 2-22                  [1, 96, 5, 5]             --\n",
              "â”‚    â”‚    â””â”€Sequential: 3-40             [1, 96, 5, 5]             9,504\n",
              "â”‚    â”‚    â””â”€Sequential: 3-41             [1, 96, 5, 5]             9,504\n",
              "â”‚    â””â”€BasicBlock: 2-23                  [1, 96, 5, 5]             --\n",
              "â”‚    â”‚    â””â”€Sequential: 3-42             [1, 96, 5, 5]             9,504\n",
              "â”‚    â”‚    â””â”€Sequential: 3-43             [1, 96, 5, 5]             9,504\n",
              "â”œâ”€AdaptiveMaxPool2d: 1-6                 [1, 96, 1, 1]             --\n",
              "â”œâ”€Linear: 1-7                            [1, 48]                   5,232\n",
              "==========================================================================================\n",
              "Total params: 133,980\n",
              "Trainable params: 133,980\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 3.13\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.79\n",
              "Params size (MB): 0.54\n",
              "Estimated Total Size (MB): 1.33\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hrv_input_size = (1, 12, 224, 224)  # For example: batch size of 1, 12 channels, 224x224 height and width\n",
        "pv_input_size = (1, 1, 224, 224)    # For example: batch size of 1, 1 channel, 224x224 height and width\n",
        "\n",
        "# You need to provide the sizes in a list if your model expects multiple inputs\n",
        "model_input_sizes = [hrv_input_size, pv_input_size]\n",
        "\n",
        "# Use torchinfo's summary function\n",
        "# The input size is passed as a list of tuples, each corresponding to the size of an input the model expects\n",
        "summary(model_light_res_inc, input_size=[(1, 12), (1, 12, 6, 6)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1 x 1 resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "layers = [4, 4, 4, 4] #For a deeper resnet with 16 total conv layers\n",
        "\n",
        "def conv_block(in_channels, out_channels, kernel_size=1, stride=1, padding=0):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv_block(in_channels, out_channels, stride=stride)\n",
        "        self.conv2 = conv_block(out_channels, out_channels)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "        out = out + identity\n",
        "        return F.relu(out, inplace=False)\n",
        "\n",
        "class ResNet_light_deep_crop1(nn.Module):\n",
        "    \n",
        "    def __init__(self, block, layers):\n",
        "        \n",
        "        super(ResNet_light_deep_crop1, self).__init__()\n",
        "        self.in_channels = 12 #reduce the stride\n",
        "        self.initial = nn.Identity()\n",
        "        #self.maxpool = nn.MaxPool2d(kernel_size=1, stride=1, padding=0)\n",
        "        self.layer1 = self._make_layer(block, 12, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 24, layers[1], stride=1)\n",
        "        self.layer3 = self._make_layer(block, 48, layers[2], stride=1)\n",
        "        self.layer4 = self._make_layer(block, 96, layers[3], stride=1)\n",
        "        self.avgpool = nn.AdaptiveMaxPool2d((1, 1))\n",
        "        # Adjust this linear layer based on the concatenated size of HRV and PV features\n",
        "        self.fc = nn.Linear(96  + 12, 48)  \n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * block.expansion),\n",
        "            )\n",
        "        layers = [block(self.in_channels, out_channels, stride, downsample)]\n",
        "        self.in_channels = out_channels * block.expansion\n",
        "        for _ in range(1, num_blocks):\n",
        "            layers.append(block(self.in_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, pv, hrv ):\n",
        "        #print(\"Initial HRV shape:\", hrv.shape)  \n",
        "        #print(\"Initial PV shape:\", pv.shape) \n",
        "        #print(f\"{pv[0]}\")\n",
        "        x = self.initial(hrv)\n",
        "        #x = self.maxpool(x)\n",
        "        #print(\"Shape after initial conv and maxpool:\", x.shape)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        #print(\"Shape after ResNet_light blocks:\", x.shape)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        #print(\"Shape after avgpool:\", x.shape)\n",
        "        x = torch.flatten(x, 1)\n",
        "        pv = torch.flatten(pv, start_dim=1)\n",
        "        #print(f\"Sshape of x = {x.shape} shape of pv = {pv.shape}\")\n",
        "        #x = torch.concat((x, pv), dim=-1)\n",
        "        #print(\"Shape after avgpool and flatten:\", x.shape)\n",
        "\n",
        "        \n",
        "        \n",
        "        #pv = pv.view(pv.size(0), -1)\n",
        "        if pv.dim() > 2:\n",
        "            pv = torch.flatten(pv, start_dim=1)\n",
        "        #print(\"Adjusted PV shape:\", pv.shape)\n",
        "\n",
        "        combined = torch.cat((x, pv), dim=1)\n",
        "\n",
        "        if self.fc.in_features != combined.shape[1]:\n",
        "            self.fc = nn.Linear(combined.shape[1], 48).to(combined.device)\n",
        "\n",
        "        out = self.fc(combined)\n",
        "        return out\n",
        "model_light_deep_res_crop1 = ResNet_light_deep_crop1(BasicBlock, layers).to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "model_light_deep_res_crop1 = ResNet_light_deep_crop1(BasicBlock, layers)\n",
        "print(model_light_deep_res_crop1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce51VGYWXoLX"
      },
      "source": [
        "## Training models\n",
        "This generates weights for the model that we can then use for validation. The weights are then saved as the model submission meaning that each time we generate weights we can then save the weights along with the associated model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "RMSE criterion and validation functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "        \n",
        "    def forward(self, predicted, actual):\n",
        "        return torch.sqrt(self.mse(predicted, actual))\n",
        "\n",
        "criterion = RMSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model_validation(model, criterion, validation_dataloader):\n",
        "    model.eval() # This is used to set the model to evaluation mode\n",
        "    with torch.no_grad(): # This is used to stop the model from storing gradients\n",
        "        losses = []\n",
        "        for pv_features, hrv_features, pv_targets in validation_dataloader:\n",
        "            pv_features, hrv_features, pv_targets = pv_features.to(device, dtype=torch.float), hrv_features.to(device, dtype=torch.float), pv_targets.to(device, dtype=torch.float)\n",
        "            predictions = model(pv_features, hrv_features)\n",
        "            loss = criterion(predictions, pv_targets)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "    model.train() # This is used to set the model back to training mode\n",
        "    \n",
        "    return sum(losses) / len(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model_validation_indv(model, criterion, validation_dataloader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    individual_losses = []  # List to store each individual loss\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        for pv_features, hrv_features, pv_targets in validation_dataloader:\n",
        "            pv_features, hrv_features, pv_targets = pv_features.to(device, dtype=torch.float), hrv_features.to(device, dtype=torch.float), pv_targets.to(device, dtype=torch.float)\n",
        "\n",
        "            predictions = model(pv_features, hrv_features)  # Get model predictions\n",
        "            \n",
        "            # Calculate loss for each individual in the batch\n",
        "            individual_batch_losses = criterion(predictions, pv_targets, reduction='none')  # This should return a tensor of losses for each item in the batch\n",
        "            \n",
        "            individual_losses.extend(individual_batch_losses.tolist())  # Convert tensor to list and append to the list of losses\n",
        "            \n",
        "    model.train()  # Set the model back to training mode\n",
        "    return individual_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "#1 x 1 validation\n",
        "BATCH_SIZE = 32#This controls the number of sites that predictions are made for I think\n",
        "\n",
        "\n",
        "#the number of sites per batch\n",
        "\n",
        "#load the data based on the previously defined functions above, the above functions can be altered to change how the data is ingested\n",
        "train_dataset = ChallengeDataset_crop1(pv, hrv, site_locations=site_locations,\n",
        "                                 start_date=\"2020-7-1\", end_date=\"2020-7-02\")  # controls which data is loaded in\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, pin_memory=True)\n",
        "\n",
        "validation_dataset = ChallengeDataset_crop1(pv, hrv, site_locations=site_locations,\n",
        "                                      start_date=\"2020-7-03\", end_date=\"2020-7-03\") \n",
        "validation_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, pin_memory=True)  # controls which data is loaded in\n",
        "model = model_light_deep_res_crop1\n",
        "criterion = RMSELoss()#nn.L1Loss()#Here we are defining the test stat as MAE\n",
        "optimiser = optim.Adam(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Solar angle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'ChallengeDataset_inc' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24656\\1906163812.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#load the data based on the previously defined functions above, the above functions can be altered to change how the data is ingested\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m train_dataset = ChallengeDataset_inc(pv_inc, hrv, site_locations=site_locations,\n\u001b[0m\u001b[0;32m      9\u001b[0m                                  start_date=\"2020-7-01\", end_date=\"2020-7-30\")  # controls which data is loaded in\n\u001b[0;32m     10\u001b[0m \u001b[0mtrain_dataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'ChallengeDataset_inc' is not defined"
          ]
        }
      ],
      "source": [
        "#1 x 1 validation\n",
        "BATCH_SIZE = 32#This controls the number of sites that predictions are made for I think\n",
        "\n",
        "\n",
        "#the number of sites per batch\n",
        "\n",
        "#load the data based on the previously defined functions above, the above functions can be altered to change how the data is ingested\n",
        "train_dataset = ChallengeDataset_inc(pv_inc, hrv, site_locations=site_locations,\n",
        "                                 start_date=\"2020-7-01\", end_date=\"2020-7-30\")  # controls which data is loaded in\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, pin_memory=True)\n",
        "\n",
        "validation_dataset = ChallengeDataset_inc(pv_inc, hrv, site_locations=site_locations,\n",
        "                                      start_date=\"2020-7-31\", end_date=\"2020-7-31\") \n",
        "validation_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, pin_memory=True)  # controls which data is loaded in\n",
        "model = model_light_res_inc\n",
        "criterion = RMSELoss()#nn.L1Loss()#Here we are defining the test stat as MAE\n",
        "optimiser = optim.Adam(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Batch 200: Training Loss: 0.6901774782687425\n",
            "     Validation Loss: 0.6259630101530115\n",
            "\n",
            "Epoch 1, Batch 400: Training Loss: 0.45198515320196747\n",
            "     Validation Loss: 0.28325673910737015\n",
            "\n",
            "Epoch 1, Batch 600: Training Loss: 0.3479954456165433\n",
            "     Validation Loss: 0.29200988040918846\n",
            "\n",
            "Epoch 1, Batch 800: Training Loss: 0.3096109548956156\n",
            "     Validation Loss: 0.3024651932046494\n",
            "\n",
            "Epoch 1, Batch 1000: Training Loss: 0.2940558145642281\n",
            "     Validation Loss: 0.2942168908319756\n",
            "\n",
            "Epoch 1, Batch 1200: Training Loss: 0.2785385711677372\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 1\n",
        "training_losses = []\n",
        "validation_losses = []\n",
        "epoch_train_losses = []\n",
        "epoch_validation_losses = []\n",
        "timestamps = []\n",
        "site_ids = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    count = 0\n",
        "\n",
        "    # Training loop\n",
        "    for i, (site_id, time_id, pv_features, hrv_features, pv_targets) in enumerate(train_dataloader):\n",
        "        timestamps.append(time_id)\n",
        "        site_ids.append(site_id)\n",
        "        optimiser.zero_grad()\n",
        "        pv_features, hrv_features, pv_targets = \\\n",
        "            pv_features.to(device, dtype=torch.float), \\\n",
        "            hrv_features.to(device, dtype=torch.float), \\\n",
        "            pv_targets.to(device, dtype=torch.float)\n",
        "\n",
        "        predictions = model(pv_features, hrv_features)\n",
        "        loss = criterion(predictions, pv_targets)\n",
        "        loss.backward()\n",
        "        optimiser.step()\n",
        "        \n",
        "        size = pv_targets.size(0)\n",
        "        running_loss += float(loss) * size\n",
        "        count += size\n",
        "       \n",
        "\n",
        "        if i % 200 == 199:\n",
        "            current_loss = running_loss / count\n",
        "            training_losses.append(current_loss)\n",
        "            print(f\"Epoch {epoch + 1}, Batch {i + 1}: Training Loss: {current_loss}\")\n",
        "\n",
        "            # Validation\n",
        "            model.eval()\n",
        "            validation_loss = 0\n",
        "            val_count = 0\n",
        "            for val_site, val_time, val_pv_features, val_hrv_features, val_pv_targets in validation_dataloader:\n",
        "                val_pv_features, val_hrv_features, val_pv_targets = \\\n",
        "                    val_pv_features.to(device, dtype=torch.float), \\\n",
        "                    val_hrv_features.to(device, dtype=torch.float), \\\n",
        "                    val_pv_targets.to(device, dtype=torch.float)\n",
        "                val_predictions = model(val_pv_features, val_hrv_features)\n",
        "                val_loss = criterion(val_predictions, val_pv_targets)\n",
        "\n",
        "                val_size = val_pv_targets.size(0)\n",
        "                validation_loss += float(val_loss) * val_size\n",
        "                val_count += val_size\n",
        "\n",
        "            validation_loss /= val_count\n",
        "            validation_losses.append(validation_loss)\n",
        "            print(f\"     Validation Loss: {validation_loss}\\n\")\n",
        "\n",
        "    epoch_train_loss = running_loss / count\n",
        "    epoch_train_losses.append(epoch_train_loss)  \n",
        "\n",
        "    print(f\"Epoch {epoch + 1} Completed: Training Loss: {epoch_train_loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Epoch 1, Batch 5400: Training Loss: 0.14787826614074961\n",
        "     Validation Loss: 0.2039671509153471\n",
        "For non normalised batch of pv_inc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1 x 1 crop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Batch 200: Training Loss: 0.1800387727841735\n",
            "     Validation Loss: 0.15766769058661717\n",
            "\n",
            "Epoch 1, Batch 400: Training Loss: 0.17691379153169692\n",
            "     Validation Loss: 0.1271176991575676\n",
            "\n",
            "Epoch 1 Completed: Training Loss: 0.16555297340308905\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 1\n",
        "training_losses = []\n",
        "validation_losses = []\n",
        "epoch_train_losses = []\n",
        "epoch_validation_losses = []\n",
        "timestamps = []\n",
        "site_ids = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    count = 0\n",
        "\n",
        "    # Training loop\n",
        "    for i, (site_id, time_id, pv_features, hrv_features, pv_targets) in enumerate(train_dataloader):\n",
        "        if epoch == 0:\n",
        "            timestamps.append(time_id)\n",
        "        site_ids.append(site_id)\n",
        "        optimiser.zero_grad()\n",
        "        pv_features, hrv_features, pv_targets = \\\n",
        "            pv_features.to(device, dtype=torch.float), \\\n",
        "            hrv_features.to(device, dtype=torch.float), \\\n",
        "            pv_targets.to(device, dtype=torch.float)\n",
        "\n",
        "        predictions = model(pv_features, hrv_features)\n",
        "        loss = criterion(predictions, pv_targets)\n",
        "        loss.backward()\n",
        "        optimiser.step()\n",
        "        \n",
        "        size = pv_targets.size(0)\n",
        "        running_loss += float(loss) * size\n",
        "        count += size\n",
        "       \n",
        "\n",
        "        if i % 200 == 199:\n",
        "            current_loss = running_loss / count\n",
        "            training_losses.append(current_loss)\n",
        "            print(f\"Epoch {epoch + 1}, Batch {i + 1}: Training Loss: {current_loss}\")\n",
        "\n",
        "            # Validation\n",
        "            model.eval()\n",
        "            validation_loss = 0\n",
        "            val_count = 0\n",
        "            for val_site, val_time, val_pv_features, val_hrv_features, val_pv_targets in validation_dataloader:\n",
        "                val_pv_features, val_hrv_features, val_pv_targets = \\\n",
        "                    val_pv_features.to(device, dtype=torch.float), \\\n",
        "                    val_hrv_features.to(device, dtype=torch.float), \\\n",
        "                    val_pv_targets.to(device, dtype=torch.float)\n",
        "                val_predictions = model(val_pv_features, val_hrv_features)\n",
        "                val_loss = criterion(val_predictions, val_pv_targets)\n",
        "\n",
        "                val_size = val_pv_targets.size(0)\n",
        "                validation_loss += float(val_loss) * val_size\n",
        "                val_count += val_size\n",
        "\n",
        "            validation_loss /= val_count\n",
        "            validation_losses.append(validation_loss)\n",
        "            print(f\"     Validation Loss: {validation_loss}\\n\")\n",
        "\n",
        "    epoch_train_loss = running_loss / count\n",
        "    epoch_train_losses.append(epoch_train_loss)  \n",
        "\n",
        "    print(f\"Epoch {epoch + 1} Completed: Training Loss: {epoch_train_loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Epoch 1, 3800: 0.15208584108733034 for fourty layers deep resnet 1x1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "batch_indices = list(range(1, len(training_losses) + 1))\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"Batch\": batch_indices,\n",
        "    \"Training Loss\": training_losses,\n",
        "    \"Validation Loss\": validation_losses\n",
        "})\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Create a new figure\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plot training and validation losses\n",
        "sns.lineplot(data=df, x=\"Batch\", y=\"Training Loss\", label=\"Training Loss\", marker='o')\n",
        "sns.lineplot(data=df, x=\"Batch\", y=\"Validation Loss\", label=\"Validation Loss\", marker='o')\n",
        "\n",
        "# Add labels and title\n",
        "plt.title('Training and Validation Loss per Batch')\n",
        "plt.xlabel('Batch Number')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "# Show the plot\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = []  # This will store each row as a dictionary\n",
        "\n",
        "for time_ids, site_id, pv_features, hrv_features, pv_targets in validation_dataloader:\n",
        "    if len(site_id) != BATCH_SIZE:\n",
        "        continue\n",
        "\n",
        "    pv_features = pv_features.to(device, dtype=torch.float)\n",
        "    hrv_features = hrv_features.to(device, dtype=torch.float)\n",
        "    pv_targets = pv_targets.to(device, dtype=torch.float)\n",
        "\n",
        "    predictions = model(pv_features, hrv_features)\n",
        "\n",
        "    predictions = predictions.detach().cpu().numpy()\n",
        "    targets = pv_targets.detach().cpu().numpy()\n",
        "\n",
        "\n",
        "    site_id = site_id.cpu().numpy() if isinstance(site_id, torch.Tensor) else site_id\n",
        "    time_ids = [time.strftime('%Y-%m-%d %H:%M:%S') if isinstance(time, datetime) else time for time in time_ids]\n",
        "\n",
        "\n",
        "    for i in range(len(predictions)):\n",
        "        timestamp = time_ids[i]\n",
        "        site = site_id[i] if isinstance(site_id, np.ndarray) else site_id\n",
        "\n",
        "\n",
        "        data.append({\n",
        "            'Timestamp': timestamp,\n",
        "            'Site': site,\n",
        "            'Prediction': predictions[i],\n",
        "            'Actual': targets[i]\n",
        "        })\n",
        "\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "data_expanded = []\n",
        "\n",
        "# Iterate over each row in your original DataFrame\n",
        "for idx, row in df.iterrows():\n",
        "    starting_timestamp = datetime.strptime(row['Timestamp'][0], '%Y-%m-%dT%H:%M:%S')\n",
        "    \n",
        "    timestamps = [(starting_timestamp + timedelta(minutes=5*i)).strftime('%Y-%m-%dT%H:%M:%S') \n",
        "                  for i in range(len(row['Prediction']))]\n",
        "    \n",
        "    num_entries = min(len(timestamps), len(row['Prediction']), len(row['Actual']))\n",
        "\n",
        "    for i in range(num_entries):\n",
        "        data_expanded.append({\n",
        "            'Timestamp': timestamps[i],\n",
        "            'Site': row['Site'],\n",
        "            'Prediction': row['Prediction'][i],\n",
        "            'Actual': row['Actual'][i]\n",
        "        })\n",
        "\n",
        "df_expanded = pd.DataFrame(data_expanded)\n",
        "\n",
        "df_results = df_expanded#unfiltered results \n",
        "\n",
        "df_results[\"Timestamp\"] = pd.to_datetime(df_results[\"Timestamp\"])\n",
        "df_filtered = df_results[df_results['Timestamp'].dt.time <= pd.Timestamp('19:00:00').time()]\n",
        "\n",
        "complete_timestamps = set(df_filtered[\"Timestamp\"].unique())\n",
        "\n",
        "def site_has_all_timestamps(group):\n",
        "    site_timestamps = set(group[\"Timestamp\"])\n",
        "    return site_timestamps == complete_timestamps\n",
        "\n",
        "complete_sites = df_filtered.groupby('Site').filter(site_has_all_timestamps)\n",
        "\n",
        "sites_with_all_timestamps = complete_sites['Site'].unique()\n",
        "\n",
        "df_final = df_filtered[df_filtered['Site'].isin(sites_with_all_timestamps)]\n",
        "\n",
        "df_final_results_filtered =  df_final#filtered results "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_expanded.to_csv(\"validation_test_1x1.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final_results_filtered.to_csv(\"validation_test_1x1_filtered.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, 200: 0.36770922265946865\n",
            "Epoch 1, 400: 0.2938720406591892\n",
            "Epoch 1, 600: 0.2535955745726824\n",
            "Epoch 1, 800: 0.2209237673971802\n",
            "Epoch 1, 1000: 0.2061016338393092\n",
            "Epoch 1, 1200: 0.20297124555955331\n",
            "Epoch 1, 1400: 0.20268771537180458\n",
            "Epoch 1, 1600: 0.19519254204817116\n",
            "Epoch 1, 1800: 0.18668482009321452\n",
            "Epoch 1, 2000: 0.1798354455381632\n",
            "Epoch 1, 2200: 0.17636673260818828\n",
            "Epoch 1, 2400: 0.17655279666806262\n",
            "Epoch 1, 2600: 0.17645797354670673\n",
            "Epoch 1, 2800: 0.1762564202211797\n",
            "Epoch 1, 3000: 0.1739811169169843\n",
            "Epoch 1, 3200: 0.17064655700756703\n",
            "Epoch 1, 3400: 0.1666287268632475\n",
            "Epoch 1, 3600: 0.16343212737494872\n",
            "Epoch 1, 3800: 0.1624090238935069\n",
            "Epoch 1, 4000: 0.16172131700254977\n",
            "Epoch 1, 4200: 0.16208061397341744\n",
            "Epoch 1, 4400: 0.16253961996598676\n",
            "Epoch 1, 4600: 0.16282881255221107\n",
            "Epoch 1, 4800: 0.16330656321098408\n",
            "Epoch 1, 5000: 0.16288286428153514\n",
            "Epoch 1, 5200: 0.16133255959918294\n",
            "Epoch 1, 5400: 0.16050589363884044\n",
            "Epoch 1, 5600: 0.1600893903902865\n",
            "Epoch 1, 5800: 0.15906826489669237\n",
            "Epoch 1, 6000: 0.1588798239408061\n",
            "Epoch 1, 6200: 0.1578739474067885\n",
            "Epoch 1, 6400: 0.15712167033547303\n",
            "Epoch 1, 6600: 0.15764752724038605\n",
            "Epoch 1, 6800: 0.15792598209973863\n",
            "Epoch 1, 7000: 0.1575658724135054\n",
            "Epoch 1, 7200: 0.15677042511628114\n",
            "Epoch 1: 0.15652976795361748\n",
            "Epoch 2, 200: 0.16302908902987837\n",
            "Epoch 2, 400: 0.1680343849910423\n",
            "Epoch 2, 600: 0.15267919967261454\n",
            "Epoch 2, 800: 0.1342501373507548\n",
            "Epoch 2, 1000: 0.1316841103453189\n",
            "Epoch 2, 1200: 0.13891755218151958\n",
            "Epoch 2, 1400: 0.14649048614049595\n",
            "Epoch 2, 1600: 0.1444659712642897\n",
            "Epoch 2, 1800: 0.14044008256971008\n",
            "Epoch 2, 2000: 0.13644477663468568\n",
            "Epoch 2, 2200: 0.13652407970533453\n",
            "Epoch 2, 2400: 0.1400584131021363\n",
            "Epoch 2, 2600: 0.1422268115922522\n",
            "Epoch 2, 2800: 0.1448521468781733\n",
            "Epoch 2, 3000: 0.14470149937458338\n",
            "Epoch 2, 3200: 0.14340563960256986\n",
            "Epoch 2, 3400: 0.14119666364865707\n",
            "Epoch 2, 3600: 0.13999147914143073\n",
            "Epoch 2, 3800: 0.14016132300327483\n",
            "Epoch 2, 4000: 0.14059709682967514\n",
            "Epoch 2, 4200: 0.14209974665726935\n",
            "Epoch 2, 4400: 0.14365483721633526\n",
            "Epoch 2, 4600: 0.14479653518161048\n",
            "Epoch 2, 4800: 0.1461392650140139\n",
            "Epoch 2, 5000: 0.14651095467954875\n",
            "Epoch 2, 5200: 0.1455918203208309\n",
            "Epoch 2, 5400: 0.14545520714242702\n",
            "Epoch 2, 5600: 0.14564708028021933\n",
            "Epoch 2, 5800: 0.14517057120992705\n",
            "Epoch 2, 6000: 0.14547395550397535\n",
            "Epoch 2, 6200: 0.14493189324264324\n",
            "Epoch 2, 6400: 0.1445631021304871\n",
            "Epoch 2, 6600: 0.14545341832591502\n",
            "Epoch 2, 6800: 0.1461146175792879\n",
            "Epoch 2, 7000: 0.14608031046523579\n",
            "Epoch 2, 7200: 0.14568031014331306\n",
            "Epoch 2: 0.14546635375772707\n",
            "Epoch 3, 200: 0.1643408320657909\n",
            "Epoch 3, 400: 0.1695881368406117\n",
            "Epoch 3, 600: 0.15409990114470323\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16800\\346693902.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0moptimiser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#resets the gradient of all the previous weights and biases used in the model, can be changed to alter the type of optimiser we use\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         predictions = model(\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[0mpv_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mhrv_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\james\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16800\\532028594.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, pv, hrv)\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;31m#print(f\"{pv[0]}\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhrv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m         \u001b[1;31m#print(\"Shape after initial conv and maxpool:\", x.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\james\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\james\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\pooling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[0m\u001b[0;32m    167\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m                             return_indices=self.return_indices)\n",
            "\u001b[1;32mc:\\Users\\james\\anaconda3\\lib\\site-packages\\torch\\_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    483\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 485\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\james\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    780\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstride\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m         \u001b[0mstride\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 782\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    783\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "batch_losses = []\n",
        "val_losses = []\n",
        "epoch_train_losses = []\n",
        "epoch_val_losses = []\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0.0##sets the starting loss at zero\n",
        "    count = 0#is used to keep track of the number of batches passed through the training model\n",
        "  \n",
        "    for i, (pv_features, hrv_features, pv_targets) in enumerate(dataloader): \n",
        "        \n",
        "        optimiser.zero_grad()#resets the gradient of all the previous weights and biases used in the model, can be changed to alter the type of optimiser we use\n",
        "        predictions = model(\n",
        "            pv_features.to(device, dtype=torch.float),\n",
        "            hrv_features.to(device, dtype=torch.float),\n",
        "        )#makes predictions based off of current batch of hrv and pv inputs\n",
        "        loss = criterion(predictions, pv_targets.to(device, dtype=torch.float))#calculates the loss between the models predictions and the actual pv\n",
        "        loss.backward()#backprops the loss\n",
        "\n",
        "        optimiser.step()#updates the parameters based on the calculated loss\n",
        "        ###for generating the training and test loss graph\n",
        "        running_loss += loss.item() * pv_targets.size(0)\n",
        "        count += pv_targets.size(0)\n",
        "        optimiser.step()\n",
        "        \n",
        "        size = int(pv_targets.size(0))#calculates the size of the first dimension of the pv_targets tensor  to determine how many data points are in the current tensor\n",
        "        running_loss += float(loss) * size\n",
        "        count += size\n",
        "        #print(count)\n",
        "        #prints the current training loss for the first 200 data points of 32 batches, then prints again once the next 200 have been computed\n",
        "        if i % 200 == 199:\n",
        "            print(f\"Epoch {epoch + 1}, {i + 1}: {running_loss / count}\")\n",
        "    epoch_train_loss = running_loss / count\n",
        "    epoch_train_losses.append(epoch_train_loss)        \n",
        "    print(f\"Epoch {epoch + 1}: {running_loss / count}\")\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Epoch 1, 4800: 0.16330656321098408 for the 6 x 6 40 layers\n",
        "Epoch 2, 2200: 0.13652407970533453 for the 6 x 6 40 layers\n",
        "Epoch 2: 0.14546635375772707 for the 6 x 6 40 layers\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "6 x 6 4 hours Epoch 1: 0.14474508166945757\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
